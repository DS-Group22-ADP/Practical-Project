{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<p align=\"center\" style=\"font-weight:bold;font-size:64px\">\n",
    "Exploratory Data Analysis\n",
    "</p>\n",
    "\n",
    "# Data Science Project (Earthquake Dataset)\n",
    "\n",
    "<p align=\"left\" style=\"margin-bottom: 0px !important;\">\n",
    "  <a href=\"https://github.com/DS-Group5-ADP/Practical-Project\"><img width=\"200\" src=\"https://gis-bucket-aswinvk28.s3.eu-west-2.amazonaws.com/adp/buildings-and-earthquakes.jpg\" alt=\"Earthquake and Data Science\" title=\"Earthquake and Data Science\" align=\"center\"></a>\n",
    "</p>\n",
    "\n",
    "<a href=\"https://github.com/DS-Group5-ADP/Practical-Project\">Project Repository</a>\n",
    "\n",
    "# [Understand building and land characteristics associated with earthquakes, by getting insights into data.](https://github.com/DS-Group5-ADP/Practical-Project)\n",
    "\n",
    "<p align=\"left\" style=\"font-style:italic;text-decoration:underline\">\n",
    "A Practical Project undertaken by students at Kingston University with Applied Data Programming for Group 22\n",
    "</p>\n",
    "\n",
    "*Under **Dr. Nabajeet Barman** supervision, the group members are:*\n",
    "\n",
    "- **Aswin Vijayakumar**, **K2142045**, <a href=\"mailto:k2142045@kingston.ac.uk\">k2142045@kingston.ac.uk</a>\n",
    "- **Prem Sai Kanigalpula**, **K2042054**, <a href=\"mailto:k2042054@kingston.ac.uk\">k2042054@kingston.ac.uk</a>\n",
    "- **Puneet Sharma**, **K2055698**, <a href=\"mailto:k2055698@kingston.ac.uk\">k2055698@kingston.ac.uk</a>\n",
    "- **Srinivas Rao Kanisetti**, **K2101945**, <a href=\"mailto:k2101945@kingston.ac.uk\">k2101945@kingston.ac.uk</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Dataset\n",
    "\n",
    "## ATTRIBUTE CLASSIFICATION OF THE DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Geographical Attributes (input_features.csv)\n",
    "\n",
    "- **1.INT.1** ***geo_level_1_id:*** Level 1 Geographical Region of a building, Ranges from 0-30\n",
    "- **2.INT.2** ***geo_level_2_id:*** Level 2 Geographical Region of a building, Ranges from 0-1427\n",
    "- **3.INT.3** ***geo_level_3_id:*** Level 3 Geographical Region of a building, Ranges from 0-12567\n",
    "\n",
    "### Numerical Measures (input_features.csv)\n",
    "\n",
    "- **4.INT.1** ***count_floors_pre_eq:*** Number of floors of a building before the earthquake\n",
    "- **5.INT.2** ***age:*** The building age (in years)\n",
    "- **6.INT.3** ***area_percentage:*** Normalized area of building footprint\n",
    "- **7.INT.4** ***height_percentage:*** Normalized height of building footprint\n",
    "- **8.INT.5** ***count_families:*** Number of families that live in a building\n",
    "\n",
    "### Main Building/Land Characteristics (input_features.csv)\n",
    "\n",
    "- **9.CATEGORICAL.1**       ***ground_floor_type:*** type of the ground floor (GFT), Discrete: f,m,v,x,z\n",
    "- **10.CATEGORICAL.2**      ***other_floor_type:*** type of construction used in higher than the ground floors (except for\n",
    "  the roof) (OFT), Discrete: j,q,s,x\n",
    "- **11.CATEGORICAL.3**      ***legal_ownership_status:*** legal ownership status of the land where the building was built,\n",
    "  Discrete: a,r,v,w\n",
    "- **12.CATEGORICAL.4**      ***plan_configuration:*** building plan configuration, Discrete: a,c,d,f,m,n,o,q,s,u\n",
    "\n",
    "### Sub Building/Land Characteristics (input_features.csv)\n",
    "\n",
    "- **13.CATEGORICAL.1**      ***land_surface_condition:*** Surface condition of the land where the building was built,\n",
    "  Discrete: n,o,t\n",
    "- **14.CATEGORICAL.2**      ***foundation_type:*** type of foundation used while building, Discrete: h,i,r,u,w\n",
    "- **15.CATEGORICAL.3**      ***roof_type:*** type of roof used while building, Discrete: n,q,x\n",
    "- **16.CATEGORICAL.4**      ***position:*** Position of the building, Discrete: n,o,t\n",
    "\n",
    "### Superstructure Construction Attributes (input_features.csv)\n",
    "\n",
    "- **17.BINARY.1** ***has_superstructure_adobe_mud:*** flag variable that indicates if the superstructure was made of\n",
    "  Adobe/Mud\n",
    "- **18.BINARY.2** ***has_superstructure_mud_mortar_stone:*** flag variable that indicates if the superstructure was made\n",
    "  of Mud Mortar - Stone\n",
    "- **19.BINARY.3** ***has_superstructure_stone_flag:*** flag variable that indicates if the superstructure was made of\n",
    "  Stone\n",
    "- **20.BINARY.4** ***has_superstructure_cement_mortar_stone:*** flag variable that indicates if the superstructure was\n",
    "  made of Cement Mortar - Stone\n",
    "- **21.BINARY.5** ***has_superstructure_mud_mortar_brick:*** flag variable that indicates if the superstructure was made\n",
    "  of Mud Mortar - Brick\n",
    "- **22.BINARY.6** ***has_superstructure_cement_mortar_brick:*** flag variable that indicates if the superstructure was\n",
    "  made of Cement Mortar - Brick\n",
    "- **23.BINARY.7** ***has_superstructure_timber:*** flag variable that indicates if the superstructure was made of Timber\n",
    "- **24.BINARY.8** ***has_superstructure_bamboo:*** flag variable that indicates if the superstructure was made of Bamboo\n",
    "- **25.BINARY.9** ***has_superstructure_rc_non_engineered:*** flag variable that indicates if the superstructure was\n",
    "  made of non-engineered reinforced concrete\n",
    "- **26.BINARY.10** ***has_superstructure_rc_engineered:*** flag variable that indicates if the superstructure was made\n",
    "  of engineered reinforced concrete\n",
    "- **27.BINARY.11** ***has_superstructure_rc_engineered:*** flag variable that indicates if the superstructure was made\n",
    "  of any other material\n",
    "\n",
    "### Secondary Usage Attributes (input_features.csv)\n",
    "\n",
    "- **28.BINARY.12** ***has_secondary_use:*** flag variable that indicates if the building was used\n",
    "  for any secondary purpose\n",
    "- **29.BINARY.13** ***has_secondary_use_agriculture:*** flag variable that indicates if the\n",
    "  building was used for agricultural purposes\n",
    "- **30.BINARY.14** ***has_secondary_use_hotel:*** flag variable that indicates if the building\n",
    "  was used as a hotel\n",
    "- **31.BINARY.15** ***has_secondary_use_rental:*** flag variable that indicates if the building\n",
    "  was used for rental purposes\n",
    "- **32.BINARY.16** ***has_secondary_use_institution:*** flag variable that indicates if the\n",
    "  building was used as a location of any institution\n",
    "- **33.BINARY.17** ***has_secondary_use_school:*** flag variable that indicates if the building\n",
    "  was used as a school\n",
    "- **34.BINARY.18** ***has_secondary_use_industry:*** flag variable that indicates if the building\n",
    "  was used for industrial purposes\n",
    "- **35.BINARY.19** ***has_secondary_use_health_post:*** flag variable that indicates if the\n",
    "  building was used as a health post\n",
    "- **36.BINARY.20** ***has_secondary_use_gov_office:*** flag variable that indicates if the\n",
    "  building was used fas a government office\n",
    "- **37.BINARY.21** ***has_secondary_use_use_police:*** flag variable that indicates if the\n",
    "  building was used as a police station\n",
    "- **38.BINARY.22** ***has_secondary_use_other:*** flag variable that indicates if the building\n",
    "  was secondarily used for other purposes\n",
    "\n",
    "### Damage Impact Attributes (target_values.csv)\n",
    "\n",
    "- **39.ORDINAL.1** ***building_id:*** unique random identifier of a building\n",
    "- **40.ORDINAL.2** ***damage_grade:*** represents a level of damage to a building that was hit by earthquake,\n",
    "    - 1 represents low damage\n",
    "    - 2 represents a medium amount of damage\n",
    "    - 3 represents almost complete destruction\n",
    "\n",
    "The dataset is a structured dataset containing information on geographical attributes and different building and land\n",
    "attributes/characteristics. The geo levels (geographical) attributes, designate a hierarchy of values increasing from 0\n",
    "onwards at each level.\n",
    "\n",
    "The dataset is also part of [Richter's Predictor: Modeling Earthquake Damage](https://www.drivendata.org/competitions/57/nepal-earthquake/page/135/) which is about Nepal Earthquake Disaster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Initial Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install plotly\n",
    "!pip install plotly==5.3.1\n",
    "# part of plotly\n",
    "!pip install -U kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2\n",
    "import seaborn as sns\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Rectangle, Circle\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import init_notebook_mode, iplot, plot\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - UTILITY FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting Utility Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_gridspec__one_main__two_side_subplots(plt):\n",
    "    # start with a square Figure\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    fig.tight_layout(pad=2.0)\n",
    "\n",
    "    gs = fig.add_gridspec(2, 2,  width_ratios=(7,4), height_ratios=(3,7),\n",
    "                          left=0.1, right=0.9, bottom=0.1, top=0.9,\n",
    "                          wspace=0.15, hspace=0.15)\n",
    "    ax_0_0 = fig.add_subplot(gs[1,0])\n",
    "\n",
    "    ax1_histx = fig.add_subplot(gs[0, 0], sharex=ax_0_0)\n",
    "    ax1_histy = fig.add_subplot(gs[1, 1], sharey=ax_0_0)\n",
    "\n",
    "    return {\"gridspec\": gs, \"ax\": ax_0_0, \"axx\": ax1_histx, \"axy\": ax1_histy, \"fig\": fig}\n",
    "\n",
    "def setup_gridspec__four_main__two_side_subplots(plt):\n",
    "    # start with a square Figure\n",
    "    fig = plt.figure(figsize=(20, 30))\n",
    "    fig.tight_layout(pad=5.0)\n",
    "\n",
    "    gs = fig.add_gridspec(4, 4,  width_ratios=(8,3,8,3), height_ratios=(3,7,3,7),\n",
    "                          left=0.1, right=0.9, bottom=0.1, top=0.9,\n",
    "                          wspace=0.15, hspace=0.15)\n",
    "    ax1 = fig.add_subplot(gs[1, 0])\n",
    "    ax2 = fig.add_subplot(gs[1, 2])\n",
    "    ax3 = fig.add_subplot(gs[3, 0])\n",
    "    ax4 = fig.add_subplot(gs[3, 2])\n",
    "\n",
    "    axx1 = fig.add_subplot(gs[0, 0], sharex=ax1)\n",
    "    axy1 = fig.add_subplot(gs[1, 1], sharey=ax1)\n",
    "\n",
    "    axx2 = fig.add_subplot(gs[0, 2], sharex=ax2)\n",
    "    axy2 = fig.add_subplot(gs[1, 3], sharey=ax2)\n",
    "\n",
    "    axx3 = fig.add_subplot(gs[2, 0], sharex=ax3)\n",
    "    axy3 = fig.add_subplot(gs[3, 1], sharey=ax3)\n",
    "\n",
    "    axx4 = fig.add_subplot(gs[2, 2], sharex=ax4)\n",
    "    axy4 = fig.add_subplot(gs[3, 3], sharey=ax4)\n",
    "\n",
    "    return {\"gridspec\": gs, \"ax\": (ax1,ax2,ax3,ax4), \"axx\": (axx1, axx2, axx3, axx4),\n",
    "            \"axy\": (axy1, axy2, axy3, axy4), \"fig\": fig}\n",
    "\n",
    "def plot_loadings_plot(plt, X_pca, df, ax, eigen_vectors=(0,1,2,3,4)):\n",
    "    # obtain color palette\n",
    "    palette = np.array(sns.color_palette(\"hls\", 10))\n",
    "    # Features x Dimensions, eigen vector is a column matrix, loadings for arrow plotting\n",
    "    loadings = pc.T\n",
    "    # plot eigen vectors\n",
    "    arrow_size, text_pos = 1.0, 1.12\n",
    "    for ii,i in enumerate(eigen_vectors):\n",
    "        ax.arrow(0,0,arrow_size*loadings[i,0], arrow_size*loadings[i,1], color = palette[ii],head_width=0.01, head_length=0.01, linewidth=2, alpha=0.4)\n",
    "        ax.text(loadings[i,0]*text_pos, loadings[i,1]*text_pos, df.columns[i], color='black',\n",
    "                 ha='center', va='center', fontsize=12, alpha=0.65)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper Utility Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make zero mean for the dataframe\n",
    "def demean_data(X_df):\n",
    "    return (X_df - X_df.mean(axis=0))\n",
    "\n",
    "# returns transformed x, prin components, var explained\n",
    "def principal_components_analysis(data):\n",
    "    # get the original dimensions of a matrix\n",
    "    dimensions = data.shape[1]\n",
    "    # make zero mean of matrix\n",
    "    z = demean_data(data)\n",
    "    # make a matrix symmetric, invertible\n",
    "    symmetric_matrix = make_a_matrix_symmetric_invertible(z)\n",
    "    # find eigen values and eigen vectors\n",
    "    (eigenvalues, eigenvectors) = np.linalg.eig(symmetric_matrix)  # 'right-hand'\n",
    "    # returns transformed matrix\n",
    "    transformed_matrix = pca_transformed(z, eigenvectors, dimensions)\n",
    "    # find the principal components\n",
    "    pc = eigenvectors.T\n",
    "    # find explained variances\n",
    "    explained_variance = np.var(transformed_matrix, axis=0, ddof=1)  # col sample var\n",
    "    # take the sum of variances to 1 degree\n",
    "    sum_of_variances = np.sum(explained_variance)\n",
    "    # normalise the variances (take the ratio)\n",
    "    explained_variance_ratio = explained_variance / sum_of_variances\n",
    "    # order everything based on explained variance ratio\n",
    "    ordering = np.argsort(explained_variance_ratio)[::-1]\n",
    "    # order the transformed matrix\n",
    "    transformed_matrix = transformed_matrix[:,ordering]\n",
    "    pc = pc[ordering,:]\n",
    "    explained_variance_ratio = explained_variance_ratio[ordering]\n",
    "    return transformed_matrix, pc, explained_variance_ratio\n",
    "\n",
    "# this code will make a non-square matrix a square matrix, a symmetric matrix as well as an invertible matrix if the determinant is non-zero\n",
    "def make_a_matrix_symmetric_invertible(z):\n",
    "    return np.dot(z.T, z)\n",
    "\n",
    "# get the transformed matrix space\n",
    "def pca_transformed(z, eigenvectors, dimensions):\n",
    "    return np.dot(z, eigenvectors[:,0:dimensions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# read input data from file\n",
    "df = pd.read_csv('https://gis-bucket-aswinvk28.s3.eu-west-2.amazonaws.com/adp/dataset/input_features.csv')\n",
    "\n",
    "# read target values from file\n",
    "target = pd.read_csv('https://gis-bucket-aswinvk28.s3.eu-west-2.amazonaws.com/adp/dataset/target_values.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### See top 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# see top 10 rows\n",
    "df.head(10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# see top 10 rows\n",
    "target.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### See bottom 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# see bottom 10 rows\n",
    "df.tail(10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# see bottom 10 rows\n",
    "target.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Checking for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# printing the duplicated rows of data in input features\n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# printing the duplicated rows of data in target values\n",
    "target[target.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Merging DataFrames\n",
    "\n",
    "* Checking for dtypes\n",
    "* Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Merge feature and target variables.\n",
    "join_df = pd.merge(df, target, on='building_id', how='left')\n",
    "join_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Finding the number of rows and the number of columns in datas\n",
    "join_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Checking for dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# checking for dtypes\n",
    "join_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# printing attribute information of the merged dataframe\n",
    "join_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# check for missing values using isnull\n",
    "join_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plotting all missing values in a heatmap to make the 39 attributes list in columns in a heatmap\n",
    "sns.heatmap(join_df.isnull().T, cbar=True, cmap=\"vlag\")\n",
    "plt.xlabel(\"Heatmap of Missing Values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Checking for Non-NA Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# count of non-NA values\n",
    "join_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Generating summary statistics\n",
    "\n",
    "* Show summary statistics\n",
    "* Obtains Rank for Each Building data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# generate summary statistics\n",
    "join_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# show the rank of individual columns in the dataset that represent their values (Their ordering) from a random data sample\n",
    "join_df.rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## - Understanding the Domain\n",
    "\n",
    "#### Attribute Set of the Dataset (Understanding the Domain)\n",
    "\n",
    "* Checking for Unique Values in the dataset\n",
    "* Creating a list of attributes under attribute set\n",
    "* Checking for zero values in numerical measures\n",
    "* Checking for missing combinations of categories in categorical attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Checking for Number of Unique Values in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# printing number of unique values in the attribute domain of the dataset\n",
    "join_df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Creating a list of attributes under the attribute set\n",
    "\n",
    "* Geographical\n",
    "* Numerical Measures\n",
    "* Main Building/Land\n",
    "* Sub Building/Land\n",
    "* Superstructure Construction\n",
    "* Secondary Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creating attribute set for geographical attributes\n",
    "geographical_attributes = ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id']\n",
    "# Creating attribute set for numerical measures\n",
    "numerical_measures = ['count_floors_pre_eq', 'age', 'area_percentage', 'height_percentage', 'count_families']\n",
    "# Creating attribute set for main categorical data involving building and land characteristics\n",
    "main_building_land_attributes = ['ground_floor_type', 'other_floor_type', 'legal_ownership_status', 'plan_configuration']\n",
    "# Creating attribute set for sub categorical data involving building and land characteristics\n",
    "sub_building_land_attributes = ['land_surface_condition', 'foundation_type', 'roof_type', 'position']\n",
    "# Creating attribute set for superstructure construction attributes\n",
    "superstructure_attributes = ['has_superstructure_adobe_mud', 'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag', 'has_superstructure_cement_mortar_stone', 'has_superstructure_mud_mortar_brick', 'has_superstructure_cement_mortar_brick', 'has_superstructure_timber', 'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered', 'has_superstructure_rc_engineered', 'has_superstructure_other']\n",
    "# Creating attribute set for secondary usage attributes\n",
    "secondary_usage_attributes = ['has_secondary_use', 'has_secondary_use_agriculture', 'has_secondary_use_hotel', 'has_secondary_use_rental', 'has_secondary_use_institution', 'has_secondary_use_school', 'has_secondary_use_industry', 'has_secondary_use_health_post', 'has_secondary_use_gov_office', 'has_secondary_use_use_police', 'has_secondary_use_other']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Checking for Unique Values in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# printing unique values of categorical variables/attributes\n",
    "for attr in (main_building_land_attributes + sub_building_land_attributes):\n",
    "    print(\"Unique Attributes for: \", attr)\n",
    "    print(join_df[attr].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Checking for zero values in numerical measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# checking zero values on numerical measures only,\n",
    "# zero values on binary and geographical attributes have direct semantic meanings\n",
    "zero_values = (join_df.loc[:, numerical_measures] == 0).astype('int32').sum(axis=0)\n",
    "zero_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plotting the count of zero values in the numerical measures\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "plt.bar(zero_values.index, zero_values.values)\n",
    "plt.xticks(zero_values.index, fontsize=15.5)\n",
    "plt.ylabel(\"No of Zero Values\", fontsize=15.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Assigning correct dtypes for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# assigning category dtype to categorical variables\n",
    "join_df = join_df.astype({x: 'category' for x in main_building_land_attributes})\n",
    "join_df = join_df.astype({x: 'category' for x in sub_building_land_attributes})\n",
    "# assigning category dtype for target variable\n",
    "join_df = join_df.astype({'damage_grade': 'category'})\n",
    "# assigning int32 for numerical measures\n",
    "join_df = join_df.astype({x: 'int32' for x in numerical_measures})\n",
    "# assigning int32 for geo level attributes\n",
    "join_df = join_df.astype({x: 'int32' for x in geographical_attributes})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of Damage Grade (A Count Plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Distribution of damage across damage levels.\n",
    "plt.figure(figsize=(12 ,8))\n",
    "ax = sns.countplot(x=\"damage_grade\", data=join_df, palette=\"flare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Checking for missing combinations in categorical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# zero values does not make any sense with categorical attributes\n",
    "# the combinations of categorical attributes may have missing entries as compared with combinations of all such attributes\n",
    "# this is relevant to the understanding of the domain\n",
    "\n",
    "# checking for missing combinations for the first set of building/land attributes (categorical attributes)\n",
    "# adding 'building_id' for groupby remaining column\n",
    "main_df = join_df.loc[:, main_building_land_attributes + ['building_id']].groupby(main_building_land_attributes).count()\n",
    "main_df.drop(labels=main_df[main_df['building_id'] == 0].index, inplace=True)\n",
    "# listing all possible cartesian product of main building/land attributes (categorical attributes)\n",
    "main_categorical_attributes_table = np.array(list(itertools.product(\n",
    "    *[join_df[attr].unique().tolist() for attr in main_building_land_attributes]))\n",
    ")\n",
    "# listing all available combinations of main building/land attributes (categorical attributes)\n",
    "# get_level_values will return MultiIndex Values according to the levels 1,2,3,4\n",
    "main_available_attributes_table = np.array([main_df.index.get_level_values(i).values.tolist() for i in range(len(main_building_land_attributes))]).T\n",
    "\n",
    "# checking for missing combinations for the second set of building/land attributes (categorical attributes)\n",
    "sub_df = join_df.loc[:, sub_building_land_attributes + ['building_id']].groupby(sub_building_land_attributes).count()\n",
    "sub_df.drop(labels=sub_df[sub_df['building_id'] == 0].index, inplace=True)\n",
    "# listing all possible cartesian product of sub building/land attributes (categorical attributes)\n",
    "sub_categorical_attributes_table = np.array(list(itertools.product(\n",
    "    *[join_df[attr].unique().tolist() for attr in sub_building_land_attributes]))\n",
    ")\n",
    "# listing all available combinations of sub building/land attributes (categorical attributes)\n",
    "sub_available_attributes_table = np.array([sub_df.index.get_level_values(i).values.tolist() for i in range(len(sub_building_land_attributes))]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plotting the missing attributes ysing matplotlib-venn\n",
    "fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(12,8))\n",
    "# create a venn diagram showing actual dataset groups of main categorical attributes as a subset of the Cartesian Product\n",
    "venn2(subsets=(len(main_categorical_attributes_table), 0, len(main_available_attributes_table)), set_labels=['All main categorical attributes from Cartesian Product', 'Available main categorical attribute combinations'],\n",
    "      ax=ax1)\n",
    "# create a venn diagram showing actual dataset groups of sub categorical attributes as a subset of the Cartesian Product\n",
    "venn2(subsets=(len(sub_categorical_attributes_table), 0, len(sub_available_attributes_table)), set_labels=['All sub categorical attributes from Cartesian Product', 'Available sub categorical attribute combinations'],\n",
    "      ax=ax2)\n",
    "# setting the titles for both venn diagrams\n",
    "ax1.set_title(\"Main Building/Land Attributes\")\n",
    "ax2.set_title(\"Sub Building/Land Attributes\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Observations about Main Categorical\n",
    "\n",
    "* There are 281 Available Attribute combinations in the dataset for Main categorical\n",
    "* There are 519 Combinations that are not registered in the dataset\n",
    "\n",
    "#### Observations about Sub Categorical\n",
    "\n",
    "* There are 139 Available Attribute combinations in the dataset for Sub Categorical\n",
    "* There are only 41 Combinations that are not registered in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Numerical Measures (Understanding the Domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Transformation Candidates Overview\n",
    "\n",
    "###### 1. Demean Data (First step of Standardisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Make zero mean for the dataframe\n",
    "def demean_data(X_df):\n",
    "    return (X_df - X_df.mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "###### 2. MinMax Scaling of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Min Max Scaling\n",
    "def min_max_scale(X_s, start=0, end=1, loc=0):\n",
    "    return (X_s - X_s.min()) / (X_s.max() - X_s.min()) * (end-start) + loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "###### 3. Normalization of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Normalizing the data\n",
    "def normalization(X_df):\n",
    "    return (X_df - X_df.mean()) / X_df.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "###### 4. Log Scaling Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Log scaling the data\n",
    "def log_scaling(X_s):\n",
    "    return np.log(X_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Histogram plot of Numerical Measures\n",
    "\n",
    "* Count of Families\n",
    "* Age\n",
    "* Area Percentage\n",
    "* Height Percentage\n",
    "* Count of Floors\n",
    "\n",
    "##### Transformation Candidates\n",
    "\n",
    "- Log Scaling\n",
    "- Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "###### Histogram plot of Numerical Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# copy the dataframe in order to preserve the original format after transformation\n",
    "numerical_df = join_df.copy()\n",
    "# selecting only numerical measures\n",
    "numerical_df = numerical_df.loc[:, numerical_measures]\n",
    "# plotting the histograms\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "fig, ax = plt.subplots(1,2, figsize=(12,8))\n",
    "numerical_df.loc[:, ['age']].hist(bins=15, figsize = (10,5), grid=False, ax=ax[0])\n",
    "numerical_df.loc[:, ['area_percentage']].hist(bins=15, figsize = (10,5), grid=False, ax=ax[1])\n",
    "ax[0].set(xlabel=\"age\", ylabel=\"Count of Buildings\")\n",
    "ax[1].set(xlabel=\"area_percentage\", ylabel=\"Count of Buildings\")\n",
    "ax[0].set_title(\"\")\n",
    "ax[1].set_title(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "age_second_skewness_coefficient = 3 * (numerical_df.age.mean() - numerical_df.age.median()) / numerical_df.age.std()\n",
    "age_first_skewness_coefficient = (numerical_df.age.mean() - numerical_df.age.mode()) / numerical_df.age.std()\n",
    "\n",
    "area_percentage_second_skewness_coefficient = 3 * (numerical_df.area_percentage.mean() - numerical_df.area_percentage.median()) / numerical_df.area_percentage.std()\n",
    "area_percentage_first_skewness_coefficient = (numerical_df.area_percentage.mean() - numerical_df.area_percentage.mode()) / numerical_df.area_percentage.std()\n",
    "\n",
    "height_percentage_second_skewness_coefficient = 3 * (numerical_df.height_percentage.mean() - numerical_df.height_percentage.median()) / numerical_df.height_percentage.std()\n",
    "height_percentage_first_skewness_coefficient = (numerical_df.height_percentage.mean() - numerical_df.height_percentage.mode()) / numerical_df.height_percentage.std()\n",
    "\n",
    "print(age_second_skewness_coefficient, age_first_skewness_coefficient)\n",
    "print(area_percentage_second_skewness_coefficient, area_percentage_first_skewness_coefficient)\n",
    "print(height_percentage_second_skewness_coefficient, height_percentage_first_skewness_coefficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Observations\n",
    "\n",
    "* Most of the numerical features show some values whose Frequency is very low as compared to the Maximum Frequency Bin\n",
    "* This is a problem of visualization with Actual Values\n",
    "\n",
    "#### Findings\n",
    "\n",
    "* Normalized Value Counts could solve this problem and allow visualization on a better scale for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "###### Histogram plot of Numerical Measures after Log Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# copying the dataframe to preserve the original format after transformation\n",
    "numerical_df = join_df.copy()\n",
    "numerical_df = numerical_df.loc[:, numerical_measures]\n",
    "# subplot of age with value counts normalized\n",
    "fig, (ax1,ax2) = plt.subplots(1,2)\n",
    "# making 0 years 1 year value for log scaling compatibility (shifting by 1 year)\n",
    "numerical_df.age += 1.0\n",
    "np.log(numerical_df.age).plot(kind='hist', figsize=(14,7), rot=0, label='Log Transformed Age', title='Log Transformed Age', density=True, ax=ax1);\n",
    "np.log(numerical_df.age).plot(kind='kde', figsize=(14,7), rot=0, label='Log Transformed Age', title='Log Transformed Age', color='red', ax=ax1);\n",
    "# subplot of area percentage with value counts normalized\n",
    "np.log(numerical_df.area_percentage).plot(kind='hist', figsize=(14,7), rot=0, label='Log Transformed Area Percentage', title='Log Transformed Area Percentage', density=True, ax=ax2);\n",
    "np.log(numerical_df.area_percentage).plot(kind='kde', figsize=(14,7), rot=0, label='Log Transformed Area Percentage', title='Log Transformed Area Percentage', color='red',ax=ax2);\n",
    "fig.suptitle(\"Kernel Density Plot and Histogram Plot of Age and Area Percentage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Observations\n",
    "\n",
    "* Now all the values are visible and the bars have increased their sizes as compared to showing less value for non-normalized values\n",
    "* Possibly, Not every attribute require log scaling\n",
    "\n",
    "#### Recommendations\n",
    "\n",
    "* However, The attributes for which the normalization seems to be essential are:\n",
    "    - Age\n",
    "    - Area Percentage\n",
    "    - Height Percentage\n",
    "* Count of Floors and Count of Families may remain the same\n",
    "* This is because their values show significant change in terms of the distribution, the distribution has become more cleaner and sharper\n",
    "* Such normalization will reduce the variance thereby enabling a machine learning algorithm to learn better\n",
    "\n",
    "#### Problem Statement\n",
    "\n",
    "* In order for the government to implement governance plans the dataset must have reported correlated property for the numerical attributes\n",
    "* Such correlation will help in understanding the relationship between two attributes such as: Count of Floors and Average Height Percentage of a Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Correlation of Numerical Features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# copy from original dataframe\n",
    "numerical_df = join_df.copy()\n",
    "numerical_df = numerical_df.loc[:, numerical_measures]\n",
    "# find correlation of the matrix\n",
    "corr = numerical_df.corr()\n",
    "# set the background gradient of correlation matrix such that higher values and lower values are distinguishable\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Observations\n",
    "\n",
    "* The Average height Percentage of a building and its count of floors before earthquake are highly correlated\n",
    "* The Age and Average Area Percentage of a building are slightly negatively correlated implying when building is old, the area becomes smaller generally\n",
    "\n",
    "#### Recommendations\n",
    "\n",
    "* These insights generate good results on the numerical attributes\n",
    "* A scatter plot of average height percentage and count of floors can visualize the building and helps in investigating one property if the another one is known"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUALITY OF MEASUREMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scatter and Line Plot of Count of Floors vs Height Percentage\n",
    "\n",
    "* Relationship between Count of Floors and Height Percentage\n",
    "\n",
    "Height Percentage may be measured by **using LIDAR data** and count of floors by a known method by the government of Nepal. There may be **quality differences** observed in the measurements. The plot provides the relationship between Height Percentage and Count of Floors.\n",
    "\n",
    "The High Variance region may denote the tall **Tower-like Buildings** that had been damaged due to Earthquake, may have been counted as 2 to 8 floors in the dataset.\n",
    "\n",
    "- The Pearson R correlation coefficient between Height Percentage and Count of Floors is **0.772734**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16,12))\n",
    "colors = sns.color_palette(\"hls\", 10)\n",
    "\n",
    "def plot_count_floors_vs_height_percentage(join_df):\n",
    "    '''\n",
    "    Plots Count of Floors and Height Percentage in a scatter plot\n",
    "    @param join_df: Main DataFrame\n",
    "    @return:\n",
    "    '''\n",
    "    # scatter plot between Count of floors and Average height Percentage\n",
    "    ax.scatter(join_df.height_percentage, join_df.count_floors_pre_eq, color=colors[5])\n",
    "    \n",
    "    # set title, xlabel and ylabel\n",
    "    ax.set(xlabel=\"Height Percentage\", ylabel=\"Count of Floors\")\n",
    "    fig.suptitle(\"Scatter and Line Plot with Confidence Bands of Count of Floors vs Height Percentage\")\n",
    "    # tight layout\n",
    "    fig.tight_layout(pad=1.0)\n",
    "    \n",
    "def plot_average_line_representing_count_floors_over_height_percentage(join_df):\n",
    "    '''\n",
    "    Plots Average Line of Count Floors over Height Percentage\n",
    "    @param join_df: Main DataFrame\n",
    "    @return:\n",
    "    '''\n",
    "    # aggregation of count floors with mean and standard error\n",
    "    g = join_df.groupby('height_percentage')['count_floors_pre_eq'].agg(['mean', 'sem'])\n",
    "    # plot the average line\n",
    "    ax.plot(g.index, g['mean'], color='green', label='Line Representing Average Count Floors vs Height Percentage', ls='dashed')\n",
    "    # plot the lower limit of the average line\n",
    "    ax.plot(g.index, g['mean']-1.96*g['sem'], color=colors[0], label='Line Representing Lower Limit', ls='dashed')\n",
    "    # plot the upper limit of the average line\n",
    "    ax.plot(g.index, g['mean']+1.96*g['sem'], color='red', label='Line Representing Upper Limit', ls='dashed')\n",
    "    # fill the confidence intervals\n",
    "    ax.fill_between(g.index, g['mean']+1.96*g['sem'], g['mean']-1.96*g['sem'], edgecolor='g', facecolor='g', alpha=0.4)\n",
    "    \n",
    "    # display the legend\n",
    "    ax.legend()\n",
    "    \n",
    "def plot_high_variance_area():\n",
    "    '''\n",
    "    Plots the High variance Area detected by the fluctuations in Area Percentage values\n",
    "    @return:\n",
    "    '''\n",
    "    # Loop over data points; create box from errors at each point\n",
    "    high_variance_box = Rectangle((23, 0), 6, 11, fill=False, ls='dashed', lw=3, color=colors[8])\n",
    "    ax.add_patch(high_variance_box)\n",
    "    ax.text(20.5, 10, \"Towers\", fontsize=24, color=colors[6])\n",
    "\n",
    "plot_count_floors_vs_height_percentage(join_df)\n",
    "plot_average_line_representing_count_floors_over_height_percentage(join_df)\n",
    "plot_high_variance_area()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between Height Percentage and Count of Floors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = join_df.loc[:, numerical_measures].corr()\n",
    "corr.iloc[:, [0]].style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "###### Bar plot of Categorical Features\n",
    "\n",
    "## Research Question 1\n",
    "\n",
    "#### What are the most frequently occurring Seismic Vulnerability Factors within Building/Land Characteristics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "**The Seismic Vulnerability Factors are**:\n",
    "\n",
    "- Land Surface Condition (LSC)\n",
    "- Foundation Type (FT)\n",
    "- Roof Type (RT)\n",
    "- Ground Floor Type (GFT)\n",
    "- Other Floor Type (OFT)\n",
    "- Position\n",
    "- Plan Configuration\n",
    "- Legal Ownership Status\n",
    "\n",
    "##### Calculation of Error Bars\n",
    "\n",
    "***\n",
    "Standard Error (s.e) = \n",
    "***\n",
    "$\\Large\\sqrt{p(1-p)}$\n",
    "\n",
    "***\n",
    "Standard Error (s.e) of n earthquakes = \n",
    "***\n",
    "$\\Large\\sqrt{n*p(1-p)}$\n",
    "\n",
    "#### Results of Value Counts of Bars\n",
    "\n",
    "###### Land Surface Condition (LSC)\n",
    "\n",
    "- $LSC(t) = 216757 $\n",
    "- $LSC(n) = 35528 $\n",
    "- $LSC(o) = 8316 $\n",
    "\n",
    "**Facts:**\n",
    "\n",
    "- According to the dataset, 't' is the most commonly occurring LSC. Considering the population of buildings before damage and after damage, the assumption is that 't' must remain the most frequently occurring construction parameter within LSC.\n",
    "- According to the [literature review](https://www.shepherdholidays.com/blog/geography-of-nepal), 't' could be Terrain and terrain surfaces are commonly seen in the Earthquake sites of Nepal.\n",
    "- From the dataset, 't' occurs with probability = **0.8318**.\n",
    "- If 't' is terrain, the literature review states Plains region, implying the assumption is 'n' is Normal and 'o' is Other.\n",
    "- hence, 'n' (Normal) occurs with probability = **0.1363**\n",
    "- and, 'o' (Other) occurs with probability = **0.0319**\n",
    "\n",
    "###### Foundation Type (FT)\n",
    "\n",
    "- $FT(r) = 219196 $\n",
    "- $FT(w) = 15118 $\n",
    "- $FT(u) = 14260 $\n",
    "- $FT(i) = 10579 $\n",
    "- $FT(h) = 1448 $\n",
    "\n",
    "**Facts:**\n",
    "\n",
    "- According to the dataset, 'r' is most commonly occuring FT. Assumption is that r will remain the most frequently occuring construction parameter within Foundation Type. \n",
    "- According to the [literature review](https://www.designingbuildings.co.uk/wiki/Building_foundations), 'r' could be Raft Foundation Type, 'w' could be Wide-Strip, 'h' could be hardcore (which is the least commonly occuring). \n",
    "- 'r' is positively correlated when compared to n (Normal) than o and t (terrain) which are negatively correlated.\n",
    "- 'h' is positively correlatd to the Terrain land surface condition with Pearson R correlation coeffiicient = **0.005329**\n",
    "- From the dataset, 'r' occurs with probability = **0.8411**.\n",
    "- hence, 'w' occurs with probability = **0.0580**\n",
    "- 'u' occurs with probability = **0.0547**\n",
    "- 'i' (integrated, because it is correlated with Roof Type 'x' which is Truss) occurs with probability = **0.0406**\n",
    "- 'h' occurs with probability = **0.0005556***\n",
    "\n",
    "###### Roof Type (RT)\n",
    "\n",
    "- $RT(n) =  182842 $\n",
    "- $RT(q) =  61576 $\n",
    "- $RT(x) =  16183 $\n",
    "\n",
    "**Facts:**\n",
    "\n",
    "- According to the dataset, 'n' is most commonly occuring RT. Assumption is that 'n' will remain the most frequently occuring construction parameter within RT. \n",
    "- According to the [literature review](https://www.designingbuildings.co.uk/wiki/Types_of_roof), 'n' could be Normal, 'q' could be Quartz and 'x' could be Truss. \n",
    "- RT 'x' is highly correlated with 'i' Foundation Type. \n",
    "- 'n' occurs with probability = **0.7016**\n",
    "- 'q' occurs with probabiility = **0.2363**\n",
    "- 'x' occurs with probability = **0.0621**\n",
    "\n",
    "###### Ground Floor Type (GFT)\n",
    "\n",
    "- $GFT(f) =  209619 $\n",
    "- $GFT(x) =  24877 $\n",
    "- $GFT(v) =  24593 $\n",
    "- $GFT(z) =  1004 $\n",
    "- $GFT(m) =  508 $\n",
    "\n",
    "**Facts:**\n",
    "\n",
    "- 'f' occurs with probability = **0.8044**\n",
    "- 'x' occurs with probability = **0.0955**\n",
    "- 'v' occurs with probability = **0.0944**\n",
    "- 'z' occurs with probability = **0.000385**\n",
    "- 'm' occurs with probability = **0.000195**\n",
    "\n",
    "###### Other Floor Type (OFT)\n",
    "\n",
    "- $OFT(q) =  165282 $\n",
    "- $OFT(x) =  43448 $\n",
    "- $OFT(j) =  39843 $\n",
    "- $OFT(s) =  12028 $\n",
    "\n",
    "**Facts:**\n",
    "\n",
    "- 'q' occurs with probability = **0.6342**\n",
    "- 'x' occurs with probability = **0.1667**\n",
    "- 'j' occurs with probability = **0.1529**\n",
    "- 's' occurs with probability = **0.0462**\n",
    "\n",
    "###### Position\n",
    "\n",
    "- $Position(s) =  202090 $\n",
    "- $Position(t) =  42896 $\n",
    "- $Position(j) =  13282 $\n",
    "- $Position(o) =  2333 $\n",
    "\n",
    "**Facts:**\n",
    "\n",
    "- 's' occurs with probability = **0.7755**\n",
    "- 't' occurs with probability = **0.1646**\n",
    "- 'j' occurs with probability = **0.05097**\n",
    "- 'o' occurs with probability = **0.000895**\n",
    "\n",
    "###### Plan Configuration\n",
    "\n",
    "- $Plan Configuration(d) =  250072 $\n",
    "- $Plan Configuration(q) =  5692 $\n",
    "- $Plan Configuration(u) =  3649 $\n",
    "- $Plan Configuration(s) =  346 $\n",
    "- $Plan Configuration(c) =  325 $\n",
    "- $Plan Configuration(a) =  252 $\n",
    "- $Plan Configuration(o) =  159 $\n",
    "- $Plan Configuration(m) =  46 $\n",
    "- $Plan Configuration(n) =  38 $\n",
    "- $Plan Configuration(f) =  22 $\n",
    "\n",
    "**Facts:**\n",
    "\n",
    "- 'd' occurs with probability = **0.9596**\n",
    "- 'q' occurs with probability = **0.0218**\n",
    "- 'u' occurs with probability = **0.0140**\n",
    "- 's' occurs with probability = **0.000133**\n",
    "- 'c' occurs with probability = **0.000125**\n",
    "- 'a' occurs with probability = **9.67e-4**\n",
    "- 'o' occurs with probability = **6.101e-4**\n",
    "- 'm' occurs with probability = **1.765e-4**\n",
    "- 'n' occurs with probability = **1.458e-4**\n",
    "- 'f' occurs with probability = **8.442e-5**\n",
    "\n",
    "###### Legal Ownership Status\n",
    "\n",
    "- $Legal Ownership Status(v) =  250939 $\n",
    "- $Legal Ownership Status(a) =  5512 $\n",
    "- $Legal Ownership Status(w) =  2677 $\n",
    "- $Legal Ownership Status(r) =  1473 $\n",
    "\n",
    "**Facts:**\n",
    "\n",
    "- 'v' occurs with probability = **0.9629**\n",
    "- 'a' occurs with probability = **0.0212**\n",
    "- 'w' occurs with probability = **0.0103**\n",
    "- 'r' occurs with probability = **5.652e-3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import make_interp_spline\n",
    "from scipy import stats\n",
    "\n",
    "colors = sns.color_palette(\"hls\", 10)\n",
    "# combine all categorical attributes from main categorical and sub categorical (Attribute Classification of the dataset)\n",
    "more_destructions_causes = join_df.loc[:, main_building_land_attributes + sub_building_land_attributes]\n",
    "\n",
    "# find errors for bar plot\n",
    "def error_bars(value_counts, no_of_earthquakes=1e8):\n",
    "    # number of such bars generated by a single earthquake\n",
    "    no_of_events = no_of_earthquakes * len(value_counts.values)\n",
    "    # calculation of probabilities\n",
    "    probabilities = value_counts / value_counts.sum()\n",
    "    # calculation of standard error by Multinomial Distribution\n",
    "    sem = [np.sqrt(no_of_events*p*(1-p)) for k,p in probabilities.iteritems()]\n",
    "    return sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_pandas_kind_bar(df, attr, ax1, c, xlabel=\"\", ylabel=\"\", title=\"\"):\n",
    "\n",
    "    # value counts of building/land characteristics\n",
    "    value_counts = df[attr].value_counts().sort_values(ascending=False)\n",
    "\n",
    "    # calculate error bars\n",
    "    errors = error_bars(value_counts)\n",
    "    yerr = np.array(errors) * 1.96\n",
    "    \n",
    "    # testing code for error bars\n",
    "    number_of_earthquakes = 1e8\n",
    "    # number of such bars generated by a single earthquake\n",
    "    no_of_events = number_of_earthquakes * len(value_counts.values)\n",
    "    # calculation of probabilities\n",
    "    probabilities = value_counts / value_counts.sum()\n",
    "    # calculation of standard error by Multinomial Distribution\n",
    "    sem = [np.sqrt(no_of_events*p*(1-p)) for k,p in probabilities.iteritems()]\n",
    "    \n",
    "    assert np.array(sem) * 1.96 == yerr, \"Test #1 Failed\"\n",
    "    \n",
    "    ax1.set_xticks(range(0,len(value_counts.index.get_level_values(0))))\n",
    "    ax1.set_xticklabels(value_counts.index.get_level_values(0))\n",
    "\n",
    "    assert [t.get_text() for t in ax1.get_xticklabels()] == value_counts.index.get_level_values(0).values.tolist(), \"Test #2 Failed\"\n",
    "\n",
    "    # plotting\n",
    "    value_counts.plot(kind='bar', rot=0, color=colors[:len(value_counts.index.get_level_values(0))], ax=ax1, yerr=yerr)\n",
    "    # setting labels\n",
    "    ax1.set(xlabel=xlabel, ylabel=ylabel, title=title)\n",
    "\n",
    "# plot subplots\n",
    "fig, ax = plt.subplots(4,2, figsize=(12,24))\n",
    "\n",
    "# subplot LSC using value counts and order by descending order\n",
    "plot_pandas_kind_bar(more_destructions_causes, \"land_surface_condition\", ax[0,0], colors[:3],\n",
    "                     xlabel=\"Land Surface Condition (LSC)\", ylabel=\"Number of Buildings\", title=\"LSC vs Events\")\n",
    "# subplot FT using value counts and order by descending order\n",
    "plot_pandas_kind_bar(more_destructions_causes, \"foundation_type\", ax[0,1], colors[:5],\n",
    "                     xlabel=\"Foundation Type (FT)\", ylabel=\"Number of Buildings\", title=\"FT vs Events\")\n",
    "# subplot RT using value counts and order by descending order\n",
    "plot_pandas_kind_bar(more_destructions_causes, \"roof_type\", ax[1,0], colors[:3],\n",
    "                     xlabel=\"Roof Type (RT)\", ylabel=\"Number of Buildings\", title=\"RT vs Events\")\n",
    "# subplot GFT using value counts and order by descending order\n",
    "plot_pandas_kind_bar(more_destructions_causes, \"ground_floor_type\", ax[1,1], colors[:5],\n",
    "                     xlabel=\"Ground Floor Type (GFT)\", ylabel=\"Number of Buildings\", title=\"GFT vs Events\")\n",
    "# subplot OFT using value counts and order by descending order\n",
    "plot_pandas_kind_bar(more_destructions_causes, \"other_floor_type\", ax[2,0], colors[:4],\n",
    "                     xlabel=\"Other Floor Type (OFT)\", ylabel=\"Number of Buildings\", title=\"OFT vs Events\")\n",
    "# subplot Position using value counts and order by descending order\n",
    "plot_pandas_kind_bar(more_destructions_causes, \"position\", ax[2,1], colors[:4],\n",
    "                     xlabel=\"Position\", ylabel=\"Number of Buildings\", title=\"Position vs Events\")\n",
    "# subplot Plan Configuration using value counts and order by descending order\n",
    "plot_pandas_kind_bar(more_destructions_causes, \"plan_configuration\", ax[3,0], colors[:10],\n",
    "                     xlabel=\"Plan Configuration\", ylabel=\"Number of Buildings\", title=\"Plan Configuration vs Events\")\n",
    "# subplot Legal Ownership Status using value counts and order by descending order\n",
    "plot_pandas_kind_bar(more_destructions_causes, \"legal_ownership_status\", ax[3,1], colors[:4],\n",
    "                     xlabel=\"Legal Ownership Status\", ylabel=\"Number of Buildings\", title=\"Legal Ownership Status vs Events\")\n",
    "# tight_layout for plot\n",
    "plt.tight_layout(pad=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation of Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = pd.get_dummies(join_df.loc[:, sub_building_land_attributes]).corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Research Question 2\n",
    "\n",
    "##### What is the Percentage of Superstructure Construction Buildings that have undergone low, medium, and high levels of damage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "###### Plot of Superstructure Attributes showing their percentage contribution towards damage grade 1,2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Melting the dataframe\n",
    "temp_df = pd.melt(join_df.loc[:, superstructure_attributes + ['damage_grade']], var_name=\"building_type\", id_vars=['damage_grade'])\n",
    "# extracting only those entries constructed with superstructure\n",
    "temp_df = temp_df.loc[temp_df['value'] == 1]\n",
    "# apply map changing from 1,2,3 to low, medium, high\n",
    "temp_df[\"damage_grade\"] = temp_df[\"damage_grade\"].map(\n",
    "    {1: \"low\", 2: \"medium\", 3: \"high\"}\n",
    ")\n",
    "# applying cross tab to calculate percentages\n",
    "df = pd.crosstab(temp_df[\"building_type\"], temp_df[\"damage_grade\"])\n",
    "# calculating percentages between groups (axis=1)\n",
    "# df = df.apply(lambda x: round(x / df.sum(axis=1) * 100, 2))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 11 superstructure attributes\n",
    "x = np.arange(11)\n",
    "plt.figure(figsize=(20,5))\n",
    "# plotting low,medium,high percentage values\n",
    "plt.bar(x-0.3, height= df[\"low\"], width=0.3)\n",
    "plt.bar(x, height= df[\"medium\"],width=0.3)\n",
    "plt.bar(x+0.3, height= df[\"high\"],width=0.3)\n",
    "# plotting xticks\n",
    "plt.xticks(x, superstructure_attributes, ha=\"left\",rotation=345)\n",
    "# setting labels and title\n",
    "plt.title=\"Damage By Buildings constructed with Structure Type\"\n",
    "plt.xlabel(\"Superstructures\")\n",
    "plt.ylabel(\"Percentage Damage\")\n",
    "plt.legend([\"low\", \"medium\", \"high\"], loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Research Question 3\n",
    "\n",
    "#### What is the distribution of building age over damage grade, and the percentage of damage for age ranges such as 0-10, 10-15, 15-30 and 30-995?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# copy the dataframe\n",
    "merged_data = join_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to represent damage levels 1,2,3 as 'Low', 'Medium' and 'High."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def represent_damage_level(merged_data):  \n",
    "    # creating an additional columns as 'damage_grade_def' to store the representation of damage levels.\n",
    "    merged_data['damage_grade_def'] = np.where(merged_data.damage_grade==1,'(1) Low',\n",
    "    np.where(merged_data.damage_grade==2,'(2) Medium',np.where(merged_data.damage_grade==3,'(3) High',0)))                                       \n",
    "represent_damage_level(merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to plot the distribution of age across different damage levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot1(merged_data, age, rt, dgd):\n",
    "    # Bar plot within plotly express is used to plot the distribution\n",
    "    fig = px.bar(merged_data.groupby(['age','damage_grade_def']).roof_type.count().reset_index().rename(columns={'roof_type':'count'}),\n",
    "    x=\"age\", y=\"count\", color=\"damage_grade_def\", title=\"Distribution of the building age over damage grade\",width=2500, height=500)\n",
    "    # Updating X axis to have the age between 0 to 995.\n",
    "    fig.update_xaxes(range=[0, 995])\n",
    "    # changing the width of bars.\n",
    "    for data in fig.data:\n",
    "      data[\"width\"] = 4.9\n",
    "    fig.show()\n",
    "plot1(merged_data, 'age', 'roof_type', 'damage_grade_def')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to plot piecharts showing distribution of damage grade, for different age range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_subplotted_pie_chart(merged_data ,col, labels, target_col):\n",
    "    # figure containing subplots is defined.\n",
    "    fig = make_subplots(rows=1, cols=4, specs=[[{'type':'domain'},\n",
    "                                                {'type':'domain'},\n",
    "                                                {'type':'domain'},\n",
    "                                                {'type':'domain'}]], subplot_titles = labels)\n",
    "    # iterating labels using for loop to plot pie charts for different age range.\n",
    "    for i,lb in enumerate(labels):\n",
    "        labeled = merged_data[merged_data[target_col]==lb]\n",
    "        counted = pd.DataFrame(labeled.groupby(col)[col].count()).rename(columns={col:'Count'}).reset_index()          \n",
    "        fig.add_trace(go.Pie(values=counted.Count, labels=counted[col], name=lb),1,i+1)\n",
    "    fig.update_layout(title_text= 'Damage grade distribution for different age range')\n",
    "    iplot(fig)\n",
    "# define labels with different age range.\n",
    "labels=['0-10','10-15','15-30','30-995']\n",
    "merged_data['age_range']=pd.qcut(merged_data.age,4,labels=labels)\n",
    "draw_subplotted_pie_chart(merged_data,'damage_grade_def',labels, 'age_range')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supporting methods\n",
    "\n",
    "* Visualization is performed using Plotly\n",
    "* Represented Histograms of Age using Stacked Bar plot\n",
    "* Pie-chart to show the breakdown of Age (in %) from 0 to Extreme Values\n",
    "\n",
    "## Facts: \n",
    "\n",
    "* Stacked barplot indicates that the maximum damage was posed to the buildings of age 10 with 4360 buildings damaged due to level 1 grade, 22370 buildings damaged with level 2 grade, and\n",
    "12166 building damaged due to level 3 grade.\n",
    "\n",
    "* Stacked barplot indicated that the buildings with lower age have had major impact as compared to the buildings of higher age.\n",
    "\n",
    "* Stacked bar plot indicates that there were some historic buildings of age 995 which have mainly had level 2 damage and impacting 822 such buildings, level 3 damage has impacted 389 buildings, level 1 damage has impacted 179 buildings.\n",
    "\n",
    "* Pie chart depicts that the percentage of damage for 'High level' damage has increased with the increase of Age Range. Percentage of damage is 27.7%, 34.3%, 37.2%, and 38.5% for the age range 0-10, 10-15, 15-30, and 30-995 respectively.\n",
    "\n",
    "* Pie chart depicts that the percentage of damage for 'Medium level' damage has increased with the increase of Age Range. Percentage of damage is 54.9%, 57.7%, 57.8%, and 58.9% for the age range 0-10, 10-15, 15-30, and 30-995 respectively.\n",
    "\n",
    "* Pie chart depicts that the percentage of damage for 'low level' damage has decreased with the increase of Age Range. Percentage of damage is 17.4%, 7.99%, 4.99%, and 2.64% for the age range 0-10, 10-15, 15-30, and 30-995 respectively.\n",
    "\n",
    "\n",
    "\n",
    "## Observations: \n",
    "\n",
    "* Most of the buildings involved in the earthquake were in the age range of 0-50.\n",
    "* New buildings with age as 0 have less number of buildings with 'High \n",
    "damage grade', whereas maximum buildings were damaged with Medium level of damage grade.\n",
    "* Percentage of 'High level damage' is increasing with the increase of building Age.\n",
    "* Percentage of 'Low level damage' is decreasing with the increase of building Age.\n",
    "* Percentage of 'Medium level damage' is increasing with the increase of building Age.\n",
    "* There were very few buildings between the age range of 120 to 994. \n",
    "\n",
    "## Answer to the Research Question: \n",
    "\n",
    "Distribution of age with respect to damage level indicates that the damage to the buildings was higher for newer buildings, specially between age 0 to 50, whereas the damage has reduced significantly with the increase of age. In contrast, new build buildings have had less damage caused as compared to the buildings of age between 5 to 15. There were very few buildings between age range 150 to 994. In additon, there were 1390 historic buildings which were 995 years old and out of which 179 had low level impact, 822 had medium level impact and 389 had high level impact.\n",
    "\n",
    "Below is the percentage of damage for different age range such as 0-10, 10-15, 15-30 and 30-995:-\n",
    "\n",
    "\n",
    "* As per piechart, percentage damage for building with age range 0-10\n",
    "    - Level 1 Damage: 17.4%\n",
    "    - Level 2 Damage: 54.9%\n",
    "    - Level 3 Damage: 27.7%\n",
    "\n",
    "* As per piechart, percentage damage for building with age range 10-15\n",
    "    - Level 1 Damage: 7.99%\n",
    "    - Level 2 Damage: 57.7%\n",
    "    - Level 3 Damage: 34.3%\n",
    "\n",
    "* As per piechart, percentage damage for building with age range 15-30\n",
    "    - Level 1 Damage: 4.99%\n",
    "    - Level 2 Damage: 57.8%\n",
    "    - Level 3 Damage: 37.2%\n",
    "\n",
    "* As per piechart, percentage damage for building with age range 30-995\n",
    "    - Level 1 Damage: 2.64%\n",
    "    - Level 2 Damage: 58.9%\n",
    "    - Level 3 Damage: 38.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Research Question 4\n",
    "\n",
    "#### What is the relationship between Area Percentage and Age?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background:**\n",
    "\n",
    "From the Summary Statistics, Age and Area Percentage have relatively high variance among the Numerical Measures. Area Percentage and Height Percentage may be computed using LIDAR data. The high variances of Area and Age are explored further here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Facts:**\n",
    "\n",
    "- There is a high variance region of Area Percentage between 100 - 200 years old buildings, which have been identified as **Medieval Buildings**. \n",
    "- There is another region consisting of 995 years old buildings, which have been identified as **Ancient Buildings**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "- Age and Area Percentage are not correlated.\n",
    "- The Pearson R correlation coefficient between Age and Area percentage is **-0.004323**. \n",
    "- There are lot of buildings constructured after the Medieval Period and hence the change in the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer to the Research Question:**\n",
    "\n",
    "- The confidence bands improve the detection of high variance regions.\n",
    "- The scatter plot shown here denotes buildings with **large footprint area** are recently constructed and they may be **Modern Buildings**. \n",
    "- The government can use this data to identify the **materials used** and **best practices** of Modern buildings and why they collapsed during the earthquake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scatter and Line Plot with Confidence Bands of Age vs Area Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16,12))\n",
    "colors = sns.color_palette(\"hls\", 10)\n",
    "\n",
    "def plot_area_percentage_vs_age(join_df):\n",
    "    '''\n",
    "    Plots Area Percentage and Age in a scatter plot\n",
    "    @param join_df: Main DataFrame\n",
    "    @return:\n",
    "    '''\n",
    "    # scatter plot between Count of floors and Average height Percentage\n",
    "    ax.scatter(join_df.age, join_df.area_percentage, color=colors[5])\n",
    "    \n",
    "    # set title, xlabel and ylabel\n",
    "    ax.set(xlabel=\"Age\", ylabel=\"Area Percentage\")\n",
    "    fig.suptitle(\"Scatter and Line Plot with Confidence Bands of Age vs Area Percentage\")\n",
    "    # tight layout\n",
    "    fig.tight_layout(pad=1.0)\n",
    "    \n",
    "def plot_average_line_representing_area_percentage_over_age(join_df):\n",
    "    '''\n",
    "    Plots Average Line of Area Percentage over Age\n",
    "    @param join_df: Main DataFrame\n",
    "    @return:\n",
    "    '''\n",
    "    # aggregation of area percentage with mean and standard error\n",
    "    g = join_df.groupby('age')['area_percentage'].agg(['mean', 'sem'])\n",
    "    # plot the average line\n",
    "    ax.plot(g.index, g['mean'], color='green', label='Line Representing Average Area Percentage over Age', ls='dashed')\n",
    "    # plot the lower limit of the average line\n",
    "    ax.plot(g.index, g['mean']-1.96*g['sem'], color=colors[0], label='Line Representing Lower Limit', ls='dashed')\n",
    "    # plot the upper limit of the average line\n",
    "    ax.plot(g.index, g['mean']+1.96*g['sem'], color='red', label='Line Representing Upper Limit', ls='dashed')\n",
    "    # fill the confidence intervals\n",
    "    ax.fill_between(g.index, g['mean']+1.96*g['sem'], g['mean']-1.96*g['sem'], edgecolor='g', facecolor='g', alpha=0.4)\n",
    "    \n",
    "    # display the legend\n",
    "    ax.legend()\n",
    "    \n",
    "def plot_high_variance_area():\n",
    "    '''\n",
    "    Plots the High variance Area detected by the fluctuations in Area Percentage values\n",
    "    @return:\n",
    "    '''\n",
    "    # Loop over data points; create box from errors at each point\n",
    "    high_variance_box = Rectangle((100, 0), 100, 45, fill=False, ls='dashed', lw=3, color=colors[8])\n",
    "    ax.add_patch(high_variance_box)\n",
    "    ax.text(210, 40, \"Medieval Buildings\", fontsize=24, color=colors[6])\n",
    "    ancient_box = Rectangle((970, 0), 30, 30, fill=False, ls='dashed', lw=3, color=colors[8])\n",
    "    ax.add_patch(ancient_box)\n",
    "    ax.text(750, 25, \"Ancient Buildings\", fontsize=24, color=colors[6])\n",
    "    modern_box = Rectangle((0, 40), 40, 55, fill=False, ls='dashed', lw=3, color=colors[8])\n",
    "    ax.add_patch(modern_box)\n",
    "    ax.text(42, 95, \"Modern Buildings\", fontsize=24, color=colors[6])\n",
    "\n",
    "plot_area_percentage_vs_age(join_df)\n",
    "plot_average_line_representing_area_percentage_over_age(join_df)\n",
    "plot_high_variance_area()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between Age and Area Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = join_df.loc[:, numerical_measures].corr()\n",
    "corr.iloc[:, [1]].style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Sub Analysis 1 - Research Question 4\n",
    "\n",
    "## The Collapse of Modern Buildings due to Earthquake\n",
    "\n",
    "### - Building and Land Characteristics for Superstructure Constructed Modern Buildings with Large Footprint Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# superstructure mask for dataframe\n",
    "superstructure_mask = ((join_df['has_superstructure_adobe_mud'] == 1) |\n",
    "                                 (join_df['has_superstructure_mud_mortar_stone'] == 1) |\n",
    "                                 (join_df['has_superstructure_stone_flag'] == 1) |\n",
    "                                 (join_df['has_superstructure_cement_mortar_stone'] == 1) |\n",
    "                                 (join_df['has_superstructure_mud_mortar_brick'] == 1) |\n",
    "                                 (join_df['has_superstructure_cement_mortar_brick'] == 1) |\n",
    "                                 (join_df['has_superstructure_timber'] == 1) |\n",
    "                                 (join_df['has_superstructure_bamboo'] == 1) |\n",
    "                                 (join_df['has_superstructure_rc_non_engineered'] == 1) |\n",
    "                                 (join_df['has_superstructure_rc_engineered'] == 1) |\n",
    "                                 (join_df['has_superstructure_other'] == 1))\n",
    "\n",
    "# modern buildings with large footprint area mask for dataframe\n",
    "modern_buildings_mask = (join_df['age'] <= 40) & (join_df['area_percentage'] >= 40)\n",
    "\n",
    "# copy the original dataframe\n",
    "categorical_df = join_df.loc[superstructure_mask & modern_buildings_mask].copy()\n",
    "# one hot encoding of categorical variables\n",
    "categorical_df = pd.get_dummies(categorical_df.loc[:, main_building_land_attributes + sub_building_land_attributes + superstructure_attributes])\n",
    "# run principal components analysis\n",
    "X_pca, pc, evr = principal_components_analysis(categorical_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Modern Buildings in that region:\", len(categorical_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA Biplot of Superstructure Constructed Buildings for Modern Buildings (with large footprint area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_plot_by_superstructures(X_pca, categorical_df, ax):\n",
    "    # scale Principal component 1\n",
    "    scalex = 0.5 / (X_pca[:,0].max() - X_pca[:,0].min())\n",
    "    # scale Principal component 2\n",
    "    scaley = 0.5 / (X_pca[:,1].max() - X_pca[:,1].min())\n",
    "    # 10 colors color pallette\n",
    "    new_palette = np.array(sns.color_palette(palette=None, n_colors=11))\n",
    "    \n",
    "    ax.scatter(X_pca[categorical_df['has_superstructure_adobe_mud'] == 1,0] * scalex, X_pca[categorical_df['has_superstructure_adobe_mud'] == 1,1] * scaley, color=new_palette[0], label='has_superstructure_adobe_mud', alpha=0.9, s=180, marker='s')\n",
    "    ax.scatter(X_pca[categorical_df['has_superstructure_mud_mortar_stone'] == 1,0] * scalex, X_pca[categorical_df['has_superstructure_mud_mortar_stone'] == 1,1] * scaley, color=new_palette[1], label='has_superstructure_mud_mortar_stone', alpha=0.9, s=180, marker='*')\n",
    "    ax.scatter(X_pca[categorical_df['has_superstructure_stone_flag'] == 1,0] * scalex, X_pca[categorical_df['has_superstructure_stone_flag'] == 1,1] * scaley, color=new_palette[2], label='has_superstructure_stone_flag', alpha=0.9, s=180, marker='X')\n",
    "    ax.scatter(X_pca[categorical_df['has_superstructure_cement_mortar_stone'] == 1,0] * scalex, X_pca[categorical_df['has_superstructure_cement_mortar_stone'] == 1,1] * scaley, color=new_palette[3], label='has_superstructure_cement_mortar_stone', alpha=0.9, s=180, marker='D')\n",
    "    ax.scatter(X_pca[categorical_df['has_superstructure_mud_mortar_brick'] == 1,0] * scalex, X_pca[categorical_df['has_superstructure_mud_mortar_brick'] == 1,1] * scaley, color=new_palette[4], label='has_superstructure_mud_mortar_brick', alpha=0.9, s=180, marker='P')\n",
    "    ax.scatter(X_pca[categorical_df['has_superstructure_cement_mortar_brick'] == 1,0] * scalex, X_pca[categorical_df['has_superstructure_cement_mortar_brick'] == 1,1] * scaley, color=new_palette[5], label='has_superstructure_cement_mortar_brick', alpha=0.9, s=180, marker='v')\n",
    "    ax.scatter(X_pca[categorical_df['has_superstructure_timber'] == 1,0] * scalex, X_pca[categorical_df['has_superstructure_timber'] == 1,1] * scaley, color=new_palette[6], label='has_superstructure_timber', alpha=0.9, s=180, marker='8')\n",
    "    ax.scatter(X_pca[categorical_df['has_superstructure_bamboo'] == 1,0] * scalex, X_pca[categorical_df['has_superstructure_bamboo'] == 1,1] * scaley, color=new_palette[7], label='has_superstructure_bamboo', alpha=0.9, s=180, marker='h')\n",
    "    ax.scatter(X_pca[categorical_df['has_superstructure_rc_non_engineered'] == 1,0] * scalex, X_pca[categorical_df['has_superstructure_rc_non_engineered'] == 1,1] * scaley, color=new_palette[8], label='has_superstructure_rc_non_engineered', alpha=0.9, s=180, marker='H')\n",
    "    ax.scatter(X_pca[categorical_df['has_superstructure_rc_engineered'] == 1,0] * scalex, X_pca[categorical_df['has_superstructure_rc_engineered'] == 1,1] * scaley, color=new_palette[9], label='has_superstructure_rc_engineered', alpha=0.9, s=180, marker='<')\n",
    "    ax.scatter(X_pca[categorical_df['has_superstructure_other'] == 1,0] * scalex, X_pca[categorical_df['has_superstructure_other'] == 1,1] * scaley, color=new_palette[10], label='has_superstructure_other', alpha=0.9, s=180, marker='>')\n",
    "    ax.legend(loc='best')\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(12,8))\n",
    "plot_scatter_plot_by_superstructures(X_pca, categorical_df, ax)\n",
    "plot_loadings_plot(plt, X_pca, categorical_df, ax, eigen_vectors=(36,39,42,11,17))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background:**\n",
    "- What were the seismic vulnerability factors that lead to the collapse of Modern Buildings (with large footprint area)?\n",
    "- Based on materials used for construction (superstructures), what can be deduced?\n",
    "\n",
    "**Facts:**\n",
    "- Most frequently occuring Building/land Characteristics are taken for analysis using PCA Biplot. \n",
    "- Scatter plot of points involving Superstructures and Modern Buildings (with large footprint area) are taken into consideration.\n",
    "\n",
    "**Observations:**\n",
    "- GFT (Ground Floor Type), FT (Foundation Type), RT (Roof Type), OFT (Other Floor Type) are aligned opposite to LSC (Land Surface Condition). \n",
    "- Brown coloured points are representing Cement Mortar Brick, and it suggests Land Surface Condition (t) is correlated to Cement Mortar Brick as it explains most variance over that region.\n",
    "- Orange coloured points represent Mud Mortar Stone and the eigen vectors indicate GFT (f), OFT (n), RT (n) and FT (r) are correlated to Mud Mortar Stone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Sub Analysis 2 - Research Question 4\n",
    "\n",
    "## The Collapse of Modern Buildings due to Earthquake\n",
    "\n",
    "### - Building and Land Characteristics for Secondary Use Modern Buildings with Large Footprint Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# secondary usage mask for dataframe\n",
    "secondary_usage_mask = ((join_df['has_secondary_use_use_police'] == 1) |\n",
    "             (join_df['has_secondary_use_gov_office'] == 1) |\n",
    "             (join_df['has_secondary_use_institution'] == 1) |\n",
    "             (join_df['has_secondary_use_health_post'] == 1) |\n",
    "             (join_df['has_secondary_use_rental'] == 1) |\n",
    "             (join_df['has_secondary_use_agriculture'] == 1) |\n",
    "             (join_df['has_secondary_use_hotel'] == 1) |\n",
    "             (join_df['has_secondary_use_industry'] == 1) |\n",
    "             (join_df['has_secondary_use_school'] == 1) |\n",
    "             (join_df['has_secondary_use_other'] == 1))\n",
    "\n",
    "# modern buildings with large footprint area mask for dataframe\n",
    "modern_buildings_mask = (join_df['age'] <= 40) & (join_df['area_percentage'] >= 40)\n",
    "\n",
    "# copy the original dataframe\n",
    "categorical_df = join_df.loc[secondary_usage_mask & modern_buildings_mask].copy()\n",
    "# one hot encoding of categorical variables\n",
    "categorical_df = pd.get_dummies(categorical_df.loc[:, main_building_land_attributes + sub_building_land_attributes + secondary_usage_attributes])\n",
    "# run principal components analysis\n",
    "X_pca, pc, evr = principal_components_analysis(categorical_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Modern Buildings in that region:\", len(categorical_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA Biplot of Secondary Use Buildings of only Modern Buildings (with large footprint area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_plot_by_secondary_use(X_pca, categorical_df, ax):\n",
    "    # scale Principal component 1\n",
    "    scalex = 0.5 / (X_pca[:,0].max() - X_pca[:,0].min())\n",
    "    # scale Principal component 2\n",
    "    scaley = 0.5 / (X_pca[:,1].max() - X_pca[:,1].min())\n",
    "    # 10 colors color pallette\n",
    "    new_palette = np.array(sns.color_palette(palette=None, n_colors=11))\n",
    "    \n",
    "    ax.scatter(X_pca[categorical_df['has_secondary_use_agriculture'] == 1,0] * scalex, X_pca[categorical_df['has_secondary_use_agriculture'] == 1,1] * scaley, color=new_palette[0], label='has_secondary_use_agriculture', alpha=0.9, s=180, marker='s')\n",
    "    ax.scatter(X_pca[categorical_df['has_secondary_use_hotel'] == 1,0] * scalex, X_pca[categorical_df['has_secondary_use_hotel'] == 1,1] * scaley, color=new_palette[1], label='has_secondary_use_hotel', alpha=0.9, s=180, marker='P')\n",
    "    ax.scatter(X_pca[categorical_df['has_secondary_use_rental'] == 1,0] * scalex, X_pca[categorical_df['has_secondary_use_rental'] == 1,1] * scaley, color=new_palette[2], label='has_secondary_use_rental', alpha=0.9, s=180, marker='X')\n",
    "    ax.scatter(X_pca[categorical_df['has_secondary_use_institution'] == 1,0] * scalex, X_pca[categorical_df['has_secondary_use_institution'] == 1,1] * scaley, color=new_palette[3], label='has_secondary_use_institution', alpha=0.9, s=180, marker='*')\n",
    "    ax.scatter(X_pca[categorical_df['has_secondary_use_school'] == 1,0] * scalex, X_pca[categorical_df['has_secondary_use_school'] == 1,1] * scaley, color=new_palette[4], label='has_secondary_use_school', alpha=0.9, s=180, marker='D')\n",
    "    ax.scatter(X_pca[categorical_df['has_secondary_use_industry'] == 1,0] * scalex, X_pca[categorical_df['has_secondary_use_industry'] == 1,1] * scaley, color=new_palette[5], label='has_secondary_use_industry', alpha=0.9, s=180, marker='8')\n",
    "    ax.scatter(X_pca[categorical_df['has_secondary_use_health_post'] == 1,0] * scalex, X_pca[categorical_df['has_secondary_use_health_post'] == 1,1] * scaley, color=new_palette[6], label='has_secondary_use_health_post', alpha=0.9, s=180, marker='v')\n",
    "    ax.scatter(X_pca[categorical_df['has_secondary_use_gov_office'] == 1,0] * scalex, X_pca[categorical_df['has_secondary_use_gov_office'] == 1,1] * scaley, color=new_palette[7], label='has_secondary_use_gov_office', alpha=0.9, s=180, marker='<')\n",
    "    ax.scatter(X_pca[categorical_df['has_secondary_use_use_police'] == 1,0] * scalex, X_pca[categorical_df['has_secondary_use_use_police'] == 1,1] * scaley, color=new_palette[8], label='has_secondary_use_use_police', alpha=0.9, s=180, marker='>')\n",
    "    ax.scatter(X_pca[categorical_df['has_secondary_use_other'] == 1,0] * scalex, X_pca[categorical_df['has_secondary_use_other'] == 1,1] * scaley, color=new_palette[9], label='has_secondary_use_other', alpha=0.9, s=180, marker='H')\n",
    "    ax.legend(loc='best')\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(12,8))\n",
    "plot_scatter_plot_by_secondary_use(X_pca, categorical_df, ax)\n",
    "plot_loadings_plot(plt, X_pca, categorical_df, ax, eigen_vectors=(36,39,42,11,17))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background:**\n",
    "- What were the seismic vulnerability factors that lead to the collapse of Modern Buildings (with large footprint area)?\n",
    "- Based on best practices of Secondary Use Buildings, what can be deduced?\n",
    "\n",
    "**Facts:**\n",
    "- Most frequently occuring Building/land Characteristics are taken for analysis using PCA Biplot. \n",
    "- Scatter plot of points involving Secondary Use and Modern Buildings (with large footprint area) are taken into consideration.\n",
    "\n",
    "**Observations:**\n",
    "- Agriculture and Hotel Buildings are prominent in the Modern Buildings. \n",
    "- All the major seismic vulnerability factors are aligned in random fashion when compared to secondary use buildings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question 5\n",
    "\n",
    "#### How are families affected due to earthquakes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_families_earthquake(colors):\n",
    "    # copy of original dataset\n",
    "    temp_df = join_df.copy()\n",
    "    # map from 1,2,3 to low,medium,high\n",
    "    temp_df[\"damage_grade\"] = temp_df[\"damage_grade\"].map(\n",
    "        {1: \"low\", 2: \"medium\", 3: \"high\"}\n",
    "    )\n",
    "    # setting figure size\n",
    "    fig = plt.figure(figsize=(12,8))\n",
    "    fig.tight_layout(pad=1.0)\n",
    "    # pandas plotting bar plot\n",
    "    ax=temp_df.groupby(\"damage_grade\")[\"count_families\"].sum().sort_values().plot.bar(color=colors[:3], width=0.8)\n",
    "    # calculating the height of bars\n",
    "    totals = []\n",
    "    for i in ax.patches:\n",
    "        totals.append(i.get_height())\n",
    "    total = sum(totals)\n",
    "    # setting the percentage values on top of each bar\n",
    "    for i in ax.patches:\n",
    "        # get_x pulls left or right; get_height pushes up or down\n",
    "        ax.text(i.get_x()+.30, i.get_height(),\n",
    "                str(round((i.get_height()/total)*100, 2))+'%', fontsize=15,\n",
    "                color='black')\n",
    "    # setting title and labels\n",
    "    fig.suptitle(\"Families Affected due to earthquake\")\n",
    "    plt.ylabel(\"Number of families\")\n",
    "    plt.xlabel(\"Damage Grade\")\n",
    "    \n",
    "colors = sns.color_palette(\"Set2\", n_colors=10)\n",
    "plot_families_earthquake(colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question 6\n",
    "\n",
    "#### If a sample is taken from the population, then which Other Floor Type category will show relatively higher Average Height Percentage?\n",
    "\n",
    "## Sub-Visualizations of RQ6\n",
    "\n",
    "### Average Height Against Other Floor Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background:**\n",
    "\n",
    "* There is a pattern between OFT and GFT as it is known by the irregularity of buildings' design.\n",
    "* Exploration of OFT and GFT vs Height Percentage is a criteria to conclude on different floor types that have undergone damage. \n",
    "\n",
    "**Facts:**\n",
    "\n",
    "* Some floors are built for specific purpose. \n",
    "* Greater the Height, greater the vibrations. \n",
    "* Floor 'j' has lesser height when compared to others.\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "* The 'j' OFT has the least average height percentage and the 's' OFT has highest average height percentage\n",
    "* The 'j' OFT and 's' OFT are almost equal in their values for Average Height Percentage Per Floor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_average_height_against_OFT(ax, colors):\n",
    "    \n",
    "    data = join_df.loc[:, ['other_floor_type', 'height_percentage']].groupby('other_floor_type', as_index=False).mean()\n",
    "    ax.barh(data.other_floor_type, data.height_percentage, color=[colors[0], 'gray', colors[2], 'gray'])\n",
    "    ax.set_xlabel(\"Averge Height Percentage\")\n",
    "    ax.set_ylabel(\"Other Floor Type (OFT)\")\n",
    "    ax.set_title(\"Other Floor type vs Average Height Percentage\")\n",
    "    \n",
    "def plot_average_height_per_floor_against_OFT(ax, colors):\n",
    "    data = join_df.loc[:, ['other_floor_type', 'height_percentage', 'count_floors_pre_eq']]\n",
    "    data['height_per_floor'] = data['height_percentage'] / data['count_floors_pre_eq']\n",
    "    data = data[[\"other_floor_type\", \"height_per_floor\"]].groupby('other_floor_type', as_index=False).mean()\n",
    "    ax.barh(data.other_floor_type, data.height_per_floor, color=[colors[0], 'gray', colors[2], 'gray'])\n",
    "    ax.set_xlabel(\"Averge Height Per Floor\")\n",
    "    ax.set_ylabel(\"Other Floor Type (OFT)\")\n",
    "    ax.set_title(\"Other Floor type vs Average Height Percentage Per Floor\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20,6))\n",
    "colors = sns.color_palette(\"hls\", 4)\n",
    "plot_average_height_against_OFT(ax[0], colors)\n",
    "plot_average_height_per_floor_against_OFT(ax[1], colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question 6\n",
    "\n",
    "## Sub-Visualizations of RQ6\n",
    "\n",
    "### Which Other Floor Type is dominant for Tower-like Buildings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background:**\n",
    "\n",
    "* The collapse of tower-like buildings presented in the IDA are not completely known.\n",
    "* The Tower-like buildings are those with average height percentage greater or equal to 23. \n",
    "\n",
    "**Facts:**\n",
    "\n",
    "* Based on Damage Grade Levels, the scatter plot of Height Percentage and OFT are plotted.\n",
    "* The effect of Damage on such buildings are found.\n",
    "* The right hand side chart shows how the average height percentage varies for OFT. \n",
    "\n",
    "**Observations:**\n",
    "* 's' OFT has buildings in Damage Grade = 2 as well as Damage Grade = 3\n",
    "* 'q', 'j', and 'x' OFT types have buildings that have undergone complete destruction.\n",
    "* 's' is lowest in this criteria and 'q' is highest with 'j' the second among the OFT types for Average Height Percentage.\n",
    "* Height contributes to a great factor in the Damage for Tower-like Buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tower_like_mask = (join_df['height_percentage'] >= 23)\n",
    "\n",
    "def plot_OFT_dominant(ax, colors):\n",
    "    data = join_df.loc[tower_like_mask, ['other_floor_type', 'height_percentage', 'damage_grade']].sort_values(by=['other_floor_type'])\n",
    "    ax.scatter(data[(data['damage_grade'] == 1) & (data['other_floor_type'] == 'j')].height_percentage, data[(data['damage_grade'] == 1) & (data['other_floor_type'] == 'j')].other_floor_type, label=\"Damage Grade 1\", color='gray', marker='s', s=180)\n",
    "    ax.scatter(data[(data['damage_grade'] == 2) & (data['other_floor_type'] == 'j')].height_percentage, data[(data['damage_grade'] == 2) & (data['other_floor_type'] == 'j')].other_floor_type, color=colors[0], marker='s', s=180)\n",
    "    ax.scatter(data[(data['damage_grade'] == 3) & (data['other_floor_type'] == 'j')].height_percentage, data[(data['damage_grade'] == 3) & (data['other_floor_type'] == 'j')].other_floor_type, color=colors[1], marker='s', s=180)\n",
    "    ax.scatter(data[(data['damage_grade'] == 1) & (data['other_floor_type'] == 'q')].height_percentage, data[(data['damage_grade'] == 1) & (data['other_floor_type'] == 'q')].other_floor_type, color='gray', s=180)\n",
    "    ax.scatter(data[(data['damage_grade'] == 2) & (data['other_floor_type'] == 'q')].height_percentage, data[(data['damage_grade'] == 2) & (data['other_floor_type'] == 'q')].other_floor_type, label=\"Damage Grade 2\", color=colors[0], s=180)\n",
    "    ax.scatter(data[(data['damage_grade'] == 3) & (data['other_floor_type'] == 'q')].height_percentage, data[(data['damage_grade'] == 3) & (data['other_floor_type'] == 'q')].other_floor_type, color=colors[1], s=180)\n",
    "    ax.scatter(data[(data['damage_grade'] == 1) & (data['other_floor_type'] == 's')].height_percentage, data[(data['damage_grade'] == 1) & (data['other_floor_type'] == 's')].other_floor_type, color='gray', marker='X', s=180)\n",
    "    ax.scatter(data[(data['damage_grade'] == 2) & (data['other_floor_type'] == 's')].height_percentage, data[(data['damage_grade'] == 2) & (data['other_floor_type'] == 's')].other_floor_type, color=colors[0], marker='X', s=180)\n",
    "    ax.scatter(data[(data['damage_grade'] == 3) & (data['other_floor_type'] == 's')].height_percentage, data[(data['damage_grade'] == 3) & (data['other_floor_type'] == 's')].other_floor_type, label=\"Damage Grade 3\", color=colors[1], marker='X', s=180)\n",
    "    ax.scatter(data[(data['damage_grade'] == 1) & (data['other_floor_type'] == 'x')].height_percentage, data[(data['damage_grade'] == 1) & (data['other_floor_type'] == 'x')].other_floor_type, color='gray', marker='*', s=180)\n",
    "    ax.scatter(data[(data['damage_grade'] == 2) & (data['other_floor_type'] == 'x')].height_percentage, data[(data['damage_grade'] == 2) & (data['other_floor_type'] == 'x')].other_floor_type, color=colors[0], marker='*', s=180)\n",
    "    ax.scatter(data[(data['damage_grade'] == 3) & (data['other_floor_type'] == 'x')].height_percentage, data[(data['damage_grade'] == 3) & (data['other_floor_type'] == 'x')].other_floor_type, color=colors[1], marker='*', s=180)\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"Height Percentage\")\n",
    "    ax.set_ylabel(\"Other Floor Type (OFT)\")\n",
    "    ax.set_title(\"Other Floor type vs Height Percentage of Tower Like Buildings\")\n",
    "    \n",
    "def plot_OFT_Average_Dominant(ax, colors):\n",
    "    data = join_df.loc[tower_like_mask, ['other_floor_type', 'height_percentage']].groupby('other_floor_type', as_index=False).mean().sort_values(by=['other_floor_type'])\n",
    "    ax.barh(data.other_floor_type, data.height_percentage, color=[colors[0], 'gray', colors[2], 'gray'])\n",
    "    ax.set_xlabel(\"Averge Height Percentage\")\n",
    "    ax.set_ylabel(\"Other Floor Type (OFT)\")\n",
    "    ax.set_title(\"Other Floor type vs Average Height Percentage of Tower Like Buildings\")\n",
    "    \n",
    "fig, ax = plt.subplots(1,2,figsize=(20,6))\n",
    "colors = sns.color_palette(\"hls\", 6)\n",
    "plot_OFT_dominant(ax[0], colors)\n",
    "plot_OFT_Average_Dominant(ax[1], colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Research Question 6 (MAIN PLOT)\n",
    "\n",
    "#### If a sample is taken from the population, then which Other Floor Type category will show relatively higher Average Height Percentage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Scatter Plot/Histograms of GFT and OFT with Age/Area Percentage/Height Percentage/Count of Floors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# setup the gridspec 2,2 with one main plot and 2 side plots on x and y axes respectively\n",
    "result = setup_gridspec__one_main__two_side_subplots(plt)\n",
    "# gridspec\n",
    "gs = result[\"gridspec\"]\n",
    "# axis\n",
    "ax = result[\"ax\"]\n",
    "# axis on top parallel to x-axis\n",
    "axx = result[\"axx\"]\n",
    "# axis on the side parallel to y-axis\n",
    "axy = result[\"axy\"]\n",
    "# figure of the plot\n",
    "fig = result[\"fig\"]\n",
    "\n",
    "def plot_scatter_bubble_numerical_vs_categorical_bar_hist_grid_no_slice(x_attr, y_attr, dimension, xlabel, ylabel, df, ax, ax_histx, ax_histy):\n",
    "    # define central tendency based aggregation functions\n",
    "    age_df = join_df.loc[:, [x_attr, y_attr, dimension]].groupby(by=[x_attr, y_attr]).mean()\n",
    "    # get ground floor type from index\n",
    "    ground_floor_type = age_df.index.get_level_values(0)\n",
    "    # get OFT from index\n",
    "    other_floor_type = age_df.index.get_level_values(1)\n",
    "    # set unique colors as per specification\n",
    "    unique_colors = ['#88E0EF', '#161E54', '#FF5151', '#FF9B6A']\n",
    "\n",
    "    assert len(np.unique(ground_floor_type)) == 5, \"Test #1 failed\"\n",
    "    assert len(np.unique(other_floor_type)) == 4, \"Test #2 Failed\"\n",
    "    assert len(unique_colors) == 4, \"Test #3 Failed\"\n",
    "    assert unique_colors == ['#88E0EF', '#161E54', '#FF5151', '#FF9B6A'], \"Test #4 Failed\"\n",
    "\n",
    "    # set xticks and xtick labels\n",
    "    ax.set_xticks(range(0,len(np.unique(ground_floor_type))))\n",
    "    ax.set_xticklabels(np.unique(ground_floor_type))\n",
    "\n",
    "    assert [t.get_text() for t in ax.get_xticklabels()] == np.unique(ground_floor_type).tolist(), \"Test #5 Failed\"\n",
    "\n",
    "    # set colors dictionary\n",
    "    colors = dict(zip(np.unique(other_floor_type), unique_colors))\n",
    "    # scatter plot 1 for averaged values\n",
    "    ax.scatter(x=ground_floor_type, y=age_df[dimension], c=[colors[of] for of in other_floor_type], marker='s', s=500, label=\"Average Height Percentage\")\n",
    "    # scatter plot 2 for actual values\n",
    "    ax.scatter(x=join_df[x_attr], y=join_df[dimension], c=[colors[of] for of in join_df[y_attr].values.tolist()], label=\"Height Percentage\", s=100)\n",
    "    # create custom legend, by creating custom lines\n",
    "    custom_lines = [Line2D([0], [0], color=colors[of], lw=4) for of in np.unique(other_floor_type)]\n",
    "    # create legend using custom lines\n",
    "    legend1 = ax.legend(custom_lines, np.unique(other_floor_type), loc=\"upper left\", title=\"Other Floor Type\", framealpha=0.1)\n",
    "    # add legend to axis\n",
    "    ax.add_artist(legend1)\n",
    "    # set labels and titles\n",
    "    ax.set(xlabel=xlabel, ylabel=ylabel)\n",
    "    ax.set_title(\"{ylabel} vs {xlabel}\".format(xlabel=xlabel, ylabel=ylabel))\n",
    "\n",
    "    # set horizontal lines separating bottom portion\n",
    "    ax.axhline(y=4, xmin=0, xmax=4, ls='dashed', color='red', label=\"Line for separating OFT 'j'\")\n",
    "    # set horizontal lines separating top portion\n",
    "    ax.axhline(y=6.5, xmin=0, xmax=4, ls='dashed', color='green', label=\"Line for separating OFT 's'\")\n",
    "    # set the legend\n",
    "    ax.legend(title=\"Scatter Point Types\")\n",
    "\n",
    "    # get value counts of ground floor type\n",
    "    counter_i = df.loc[:, [x_attr]].value_counts()\n",
    "    # plot bar plot\n",
    "    ax_histx.bar(counter_i.index.get_level_values(0), counter_i.values)\n",
    "\n",
    "    # set xticks and xtick labels\n",
    "    ax_histx.set_xticks(range(0,len(np.unique(ground_floor_type))))\n",
    "    ax_histx.set_xticklabels(np.unique(ground_floor_type))\n",
    "\n",
    "    assert [t.get_text() for t in ax_histx.get_xticklabels()] == np.unique(ground_floor_type).tolist(), \"Test #6 Failed\"\n",
    "\n",
    "    # get histograms for damage grade 1,2,3\n",
    "    hist_y1 = join_df.loc[join_df['damage_grade'] == 1][dimension]\n",
    "    hist_y2 = join_df.loc[join_df['damage_grade'] == 2][dimension]\n",
    "    hist_y3 = join_df.loc[join_df['damage_grade'] == 3][dimension]\n",
    "    # plot histograms for 1,2,3 respectively\n",
    "    ax_histy.hist(hist_y1, orientation='horizontal', label='1')\n",
    "    ax_histy.hist(hist_y2, orientation='horizontal', label='2')\n",
    "    ax_histy.hist(hist_y3, orientation='horizontal', label='3')\n",
    "    # set legend for side subplot (y-axis)\n",
    "    ax_histy.legend()\n",
    "    # set labels\n",
    "    ax_histy.set(xlabel='Count', ylabel=\"Multiple Histograms of {ylabel} over Damage Grade\".format(ylabel=ylabel))\n",
    "    \n",
    "    # set super title for figure\n",
    "    fig.suptitle(\"Average Height Percentage vs Ground Floor Type Distinguished by Other Floor Type (color) and Quantity of values (size)\")\n",
    "\n",
    "plot_scatter_bubble_numerical_vs_categorical_bar_hist_grid_no_slice('ground_floor_type', 'other_floor_type', 'height_percentage',\n",
    "                                                                    'Ground Floor Type', 'Height Percentage', join_df, ax=ax, ax_histx=axx, ax_histy=axy)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background**\n",
    "\n",
    "* In an earthquake-affected site, if a building inspector visits the site, then can he establish if the sample of population he has taken will have on an average higher height percentage for OFT 's' compared to OFT 'j'\n",
    "* The impact of Height Percentage on Tower-like Buildings has been established\n",
    "\n",
    "**Facts:**\n",
    "\n",
    "* The scatter plot of height vs Ground Floor Type is plotted\n",
    "* Additionally, the average height is plotted with higher size dimension\n",
    "* The side histograms indicate the distribution of Height Percentage over Damage Grade\n",
    "* The top bar chart (histogram) shows frequency of occurence of GFT types in the dataset\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "* The Tower-like buildings do not have any buildings in Damage Grade 1\n",
    "* The Average Height percentage for population is higher for OFT 's' (in fact highest) than OFT 'j' (which is lowest)\n",
    "* The distribution of Ground Floor Type has been discussed in most commonly occuring Seismic Vulnerability Factors, which says GFT 'f' is the most frequent\n",
    "* The Histogram of Height Percentage is majorly over **2 to 10 Height Percentage** which is also seen in the Scatter plot between Height Percentage and Count of Floors\n",
    "* There is a clear line separating OFT 'j' and other OFT types\n",
    "* There is a clear line separating OFT 's' and other OFT types\n",
    "* OFT 's' shows an average height percentage as higher set of values for each Ground Floor Type (GFT)\n",
    "* OFT 'j' shows an average height percentage as lower set of values for each Ground Floor Type (GFT)\n",
    "* There is a pattern for such irregularity in the designs because it can be established that some buildings have higher Height Percentage for 's' compared to 'j' but some buildings do have lower height percentage for 's' compared to 'j' (which is for Tower like buildings)\n",
    "* This fact leads to the pattern of irregularity in the buildings' design which may be due to design crieteria or bad practices of designs.\n",
    "\n",
    "**Answer to the Research Question:**\n",
    "\n",
    "* A statistical test in Student's T-test has been shown to prove that there is no significant difference between mean of the population and the mean of the sample and the null hypothesis is true.\n",
    "* A building inspector who comes to the site cannot easily establish the OFT 'j' as the lowest or OFT 's' as the highest height for buildings taken on an average even though on an average they are separated as per the lines.\n",
    "* The building inspector **has to check the side histograms of Average Height Percentage** over Damage Grade 2 and Damage Grade 3 and if the height falls **within the histograms (2 to 10 % Height)**, then he may be able to establish the OFT for that building given Tower-like buildings are excluded.\n",
    "* The Building inspector cannot say what GFT type the bulding could be but he can say with a probability that GFT could be 'f' is **0.8044**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question 6\n",
    "\n",
    "#### If a sample is taken from the population, then which Other Floor Type category will show relatively higher Average Height Percentage?\n",
    "\n",
    "## Sub Answer of RQ6\n",
    "\n",
    "### Establishing the Mean of Sample picked is same as Mean of Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def analyze_alpha(averages, null_hypothesis_mean=0.0):\n",
    "    \"\"\"\n",
    "    Perform a t-test with the null hypothesis being that the expected mean return is zero.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    t_value\n",
    "        T-statistic from t-test\n",
    "    p_value\n",
    "        Corresponding p-value\n",
    "    \"\"\"\n",
    "    one_sided = True\n",
    "    two_tailed = False\n",
    "    mode = 1 if two_tailed else 2\n",
    "\n",
    "    t_value, p_value = stats.ttest_1samp(averages, null_hypothesis_mean)\n",
    "\n",
    "    return t_value, p_value / mode\n",
    "\n",
    "def evaluate_gft_oft_t_test_inference_by_simulation():\n",
    "    p_s = []\n",
    "    # 10 iterations\n",
    "    for i in range(10):\n",
    "        averages = []\n",
    "        # 100 simulations of samples\n",
    "        for i in range(100):\n",
    "            # 100 buildings in a particular geographical region\n",
    "            sample_df = join_df.sample(100)\n",
    "            if len(sample_df.loc[(sample_df['ground_floor_type'] == 'f') & \n",
    "                                 (sample_df['other_floor_type'] == 'j')]):\n",
    "                averages.append(sample_df.loc[:, ['ground_floor_type', 'other_floor_type', 'height_percentage']]\n",
    "                                .groupby(['ground_floor_type', 'other_floor_type']).mean()\n",
    "                            .loc[('f', 'j')].height_percentage)\n",
    "        net_average = \\\n",
    "        join_df.loc[:, ['ground_floor_type', 'other_floor_type', 'height_percentage']]\\\n",
    "    .groupby(['ground_floor_type', 'other_floor_type']).mean().loc[('f', 'j')].height_percentage\n",
    "        t, p = analyze_alpha(averages, null_hypothesis_mean=net_average)\n",
    "        p_s.append(p)\n",
    "        print(\"t_test value = \", t, \" p_value = \", p)\n",
    "    print(\"Average p-value: \", np.mean(p_s))\n",
    "    \n",
    "evaluate_gft_oft_t_test_inference_by_simulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background:**\n",
    "\n",
    "* Inference by simulation is required to answer the Research Question\n",
    "* A significance value of <= 0.05 will imply that there is significant difference between mean of population and mean of sample\n",
    "\n",
    "**Facts:**\n",
    "\n",
    "* A sample of 100 buildings are taken at a single simulation.\n",
    "* The averages of 100 samples over 100 simulations are recorded and compared against the null hypothesis mean. \n",
    "* 10 iteratons of such simulations are shown in this t-test simulation\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "* All the p-value of every t-test simulation exceeds, p >= 0.05\n",
    "* The average p-value of all simulations is about **0.20 to 0.30**\n",
    "\n",
    "**Answer to Research Question:**\n",
    "\n",
    "* There is no significance obtained in comparing the mean of population and mean of sample by difference of means using Student T-test\n",
    "* This implies the sample mean may be the same as the population mean.\n",
    "* The building inspector can investigate the building based on the statistics results on Average Height Percentage and suggest if the mean is similar to the population mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question 7\n",
    "\n",
    "#### If a sample of RC Engineered Superstructures is taken from the population, on an average for the Foundation Type ‘u’, will Age be relatively higher compared to other Foundation Types?\n",
    "\n",
    "## Sub Visualizations of RQ7\n",
    "\n",
    "### Modern/Medieval/Ancient Buildings - Scatter plot of Age vs Height for different Foundation Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background:**\n",
    "\n",
    "* The Age distribution as shown in RQ3 has a lot of buildings between 10 and 20 whereas the extreme values lie at 995 years old.\n",
    "* The Scatter plot in RQ4 differentiates between Ancient, Medieval and Modern Buildings\n",
    "\n",
    "**Facts:**\n",
    "\n",
    "* Scatter plot of **\"Modern Buildings with Large Footprint Area\"**, **\"Medieval Buildings\"** and **\"Ancient (Traditional) Buildings\"** have been provided here\n",
    "* Scatter plot has been differentiated by Foundation types\n",
    "* Scatter plot of Height Percentage vs Age has been shown\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "* The **Modern Buildings with Large Footprint Area** Scatter plot shows many FT (u) type below a certain height percentage.\n",
    "* The **Modern Buildings with Large Footprint Area** also shows many FT (i) with high Height Percentage.\n",
    "* The separation line indicates greater Average Height for FT (i) as compared to FT (u)\n",
    "* This implies 'i' stands for scalability (greater height) and could be assumed as Integrated Foundation Type\n",
    "* This leads to the discussion that there are a lot of 'u' Foundation Types that got damaged within Modern Buildings as compared to the 'r' FT that exists as most frequently occuring factor, overall.\n",
    "* This indicates the impact of 'u' was large on Modern Buildings, and gives rise to new FT definition which can be assumed as 'Underwater' Foundation Type.\n",
    "* Medieval and Ancient Buildings show r as dominant type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_buildings_age_vs_height_foundation_types(ax, colors, kind=\"medieval\"):\n",
    "    if kind == 'medieval':\n",
    "        # medieval buildings mask\n",
    "        buildings_mask = (join_df['age'] >= 100) & (join_df['age'] <= 200) & (join_df['area_percentage'] >= 0) & (join_df['area_percentage'] <= 45)\n",
    "        # set title and labels\n",
    "        ax.set(xlabel=\"Age\", ylabel=\"Height Percentage\", title=\"Medieval Buildings\")\n",
    "    elif kind == 'modern':\n",
    "        # modern buildings with large footprint area mask for dataframe\n",
    "        buildings_mask = (join_df['age'] <= 40) & (join_df['area_percentage'] >= 40)\n",
    "        # set title and labels\n",
    "        ax.set(xlabel=\"Age\", ylabel=\"Height Percentage\", title=\"Modern Buildings with Large Footprint Area\")\n",
    "    elif kind == 'ancient':\n",
    "        # ancient buildings\n",
    "        buildings_mask = (join_df['age'] == 995)\n",
    "        # set title and labels\n",
    "        ax.set(xlabel=\"Age\", ylabel=\"Height Percentage\", title=\"Ancient Buildings\")\n",
    "    \n",
    "    buildings = join_df.loc[buildings_mask, ['age', 'height_percentage', 'foundation_type']]\n",
    "    ft_h_mask = buildings[\"foundation_type\"] == \"h\"\n",
    "    ft_i_mask = buildings[\"foundation_type\"] == \"i\"\n",
    "    ft_r_mask = buildings[\"foundation_type\"] == \"r\"\n",
    "    ft_u_mask = buildings[\"foundation_type\"] == \"u\"\n",
    "    ft_w_mask = buildings[\"foundation_type\"] == \"w\"\n",
    "    ax.scatter(buildings.loc[ft_h_mask, 'age'], buildings.loc[ft_h_mask, 'height_percentage'], label=\"Foundation Type (h)\", color=colors[0], marker='s', s=180)\n",
    "    ax.scatter(buildings.loc[ft_i_mask, 'age'], buildings.loc[ft_i_mask, 'height_percentage'], label=\"Foundation Type (i)\", color=colors[1], marker='H', s=180)\n",
    "    ax.scatter(buildings.loc[ft_r_mask, 'age'], buildings.loc[ft_r_mask, 'height_percentage'], label=\"Foundation Type (r)\", color=colors[2], marker='D', s=180)\n",
    "    ax.scatter(buildings.loc[ft_u_mask, 'age'], buildings.loc[ft_u_mask, 'height_percentage'], label=\"Foundation Type (u)\", color=colors[3], marker='P', s=180)\n",
    "    ax.scatter(buildings.loc[ft_w_mask, 'age'], buildings.loc[ft_w_mask, 'height_percentage'], label=\"Foundation Type (w)\", color=colors[4], marker='*', s=180)\n",
    "    \n",
    "    if kind == 'modern':\n",
    "        ax.axhline(y=11, xmin=0, xmax=40, ls='dashed', color='red', label=\"Line for separating Foundation Type (i) and FT (u)\")\n",
    "        \n",
    "    ax.legend()\n",
    "    \n",
    "def plot_buildings_histogram_foundation_type(ax1, ax2, colors, kind='medieval'):\n",
    "    if kind == 'medieval':\n",
    "        # medieval buildings mask\n",
    "        buildings_mask = (join_df['age'] >= 100) & (join_df['age'] <= 200) & (join_df['area_percentage'] >= 0) & (join_df['area_percentage'] <= 45)\n",
    "        # set title and labels\n",
    "        ax1.set(xlabel=\"Foundation Type\", ylabel=\"Count\", title=\"Medieval Buildings\")\n",
    "        ax2.set(xlabel=\"Foundation Type\", ylabel=\"Age\", title=\"Medieval Buildings\")\n",
    "    elif kind == 'modern':\n",
    "        # modern buildings with large footprint area mask for dataframe\n",
    "        buildings_mask = (join_df['age'] <= 40) & (join_df['area_percentage'] >= 40)\n",
    "        # set title and labels\n",
    "        ax1.set(xlabel=\"Foundation Type\", ylabel=\"Count\", title=\"Modern Buildings with Large Footprint Area\")\n",
    "        ax2.set(xlabel=\"Foundation Type\", ylabel=\"Age\", title=\"Modern Buildings with Large Footprint Area\")\n",
    "    elif kind == 'ancient':\n",
    "        # ancient buildings\n",
    "        buildings_mask = (join_df['age'] == 995)\n",
    "        # set title and labels\n",
    "        ax1.set(xlabel=\"Foundation Type\", ylabel=\"Count\", title=\"Ancient Buildings\")\n",
    "        ax2.set(xlabel=\"Foundation Type\", ylabel=\"Age\", title=\"Ancient Buildings\")\n",
    "        \n",
    "    buildings_count = join_df.loc[buildings_mask, ['age', 'foundation_type']].groupby('foundation_type', as_index=False).count()\n",
    "    buildings_age = join_df.loc[buildings_mask, ['age', 'foundation_type']].groupby('foundation_type', as_index=False).mean()\n",
    "    ax1.bar(buildings_count.foundation_type, buildings_count.age)\n",
    "    ax2.bar(buildings_age.foundation_type, buildings_age.age)\n",
    "    \n",
    "fig, ax = plt.subplots(3, 3, figsize=(20,16))\n",
    "colors = sns.color_palette(\"hls\", 5)\n",
    "plot_buildings_age_vs_height_foundation_types(ax[0,1], colors, 'medieval')\n",
    "plot_buildings_age_vs_height_foundation_types(ax[0,0], colors, 'modern')\n",
    "plot_buildings_age_vs_height_foundation_types(ax[0,2], colors, 'ancient')\n",
    "plot_buildings_histogram_foundation_type(ax[1,1], ax[2,1], colors, kind='medieval')\n",
    "plot_buildings_histogram_foundation_type(ax[1,0], ax[2,0], colors, kind='modern')\n",
    "plot_buildings_histogram_foundation_type(ax[1,2], ax[2,2], colors, kind='ancient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Research Question 7 (MAIN PLOT)\n",
    "\n",
    "#### If a sample of RC Engineered Superstructures is taken from the population, on an average for the Foundation Type ‘u’, will Age be relatively higher compared to other Foundation Types?\n",
    "\n",
    "##### Plot of Age and Damage Grade vs Foundation Type Sliced by RC Engineered Superstructures Distinguished by Amount of Buildings Damaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# setup the gridspec 2,2 with one main plot and 2 side plots on x and y axes respectively\n",
    "result = setup_gridspec__one_main__two_side_subplots(plt)\n",
    "# gridspec\n",
    "gs = result[\"gridspec\"]\n",
    "# axis\n",
    "ax = result[\"ax\"]\n",
    "# axis on top parallel to x-axis\n",
    "axx = result[\"axx\"]\n",
    "# axis on the side parallel to y-axis\n",
    "axy = result[\"axy\"]\n",
    "# figure of the plot\n",
    "fig = result[\"fig\"]\n",
    "\n",
    "def plot_scatter_bubble_numerical_vs_categorical_bar_bar_sliced(sizes_tuple, xlabel, ylabel, sliced_by, slice_idx,\n",
    "                                                                 categorical_dimension, numerical_dimension, df, ax, ax_histx, ax_histy):\n",
    "    unique_colors = ['#88E0EF', '#161E54', '#FF5151', '#FF9B6A', '#BBDFC8']\n",
    "    var_df = df.loc[slice_idx, [numerical_dimension, categorical_dimension]].groupby(by=[categorical_dimension], as_index=False).count()\n",
    "    age_df = df.loc[slice_idx, [numerical_dimension, categorical_dimension]].groupby(by=[categorical_dimension], as_index=False).mean()\n",
    "    age_df.index = age_df[categorical_dimension]\n",
    "\n",
    "    assert len(unique_colors) == 5, \"Test #1 Failed\"\n",
    "    assert len(var_df[categorical_dimension]) == 5, \"Test #2 Failed\"\n",
    "    assert len(age_df[categorical_dimension]) == 5, \"Test #3 Failed\"\n",
    "    \n",
    "    # set xticks and xtick labels\n",
    "    ax.set_xticks(range(0,len(age_df[categorical_dimension])))\n",
    "    ax.set_xticklabels(age_df[categorical_dimension].values)\n",
    "    \n",
    "    assert [t.get_text() for t in ax.get_xticklabels()] == age_df[categorical_dimension].values.tolist(), \"Test #4 Failed\"\n",
    "    \n",
    "    counter_i = df.loc[slice_idx, [categorical_dimension]].value_counts().sort_index(ascending=True)\n",
    "    colors = dict(zip(age_df.index.values, unique_colors))\n",
    "    scatter = ax.scatter(age_df.index.values, age_df[numerical_dimension], c=[colors[ft] for ft in colors], s=sizes_tuple[0](var_df[numerical_dimension])*sizes_tuple[1])\n",
    "    ax.set(xlabel=xlabel, ylabel=ylabel)\n",
    "    ax.set_title(\"{ylabel} vs {xlabel} Sliced by {sliced_by}\".format(xlabel=xlabel, ylabel=ylabel, sliced_by=sliced_by))\n",
    "    custom_lines = [Line2D([0], [0], color=colors[dim], lw=4) for dim in age_df.index.values]\n",
    "    legend1 = ax.legend(custom_lines, age_df.index.values, loc=\"upper left\", title=\"Foundation Type\", framealpha=0.1)\n",
    "    ax.add_artist(legend1)\n",
    "    handles, labels = scatter.legend_elements(prop=\"sizes\", alpha=0.1)\n",
    "    legend2 = ax.legend(handles, labels, loc=\"upper right\", title=\"Log Damage Impact\", framealpha=0.1)\n",
    "    ax_histx.bar(counter_i.index.get_level_values(0), counter_i.values)\n",
    "    ax_histx.set(xlabel=xlabel, ylabel='Count')\n",
    "    ax_histx.set_title(\"Histogram of {xlabel}\".format(xlabel=xlabel))\n",
    "    \n",
    "    # set xticks and xtick labels\n",
    "    ax_histx.set_xticks(range(0,len(age_df[categorical_dimension])))\n",
    "    ax_histx.set_xticklabels(age_df[categorical_dimension].values)\n",
    "    \n",
    "    assert [t.get_text() for t in ax_histx.get_xticklabels()] == age_df[categorical_dimension].values.tolist(), \"Test #5 Failed\"\n",
    "    \n",
    "    ax_histy.barh(age_df[numerical_dimension], var_df[numerical_dimension])\n",
    "    ax_histy.set(xlabel='Count', ylabel=\"Damage Impact caused over Average Age grouped by Foundation Type\")\n",
    "    \n",
    "    fig.suptitle(\"Age vs Foundation Type Sliced by RC Engineered Superstructures Distinguished by Amount of Buildings Damaged\", y=0.95)\n",
    "\n",
    "plot_scatter_bubble_numerical_vs_categorical_bar_bar_sliced(sizes_tuple=(np.log, 1e2), xlabel='Foundation Type', ylabel='Avg. Age',\n",
    "                                                             sliced_by='RC Engineered', slice_idx=join_df['has_superstructure_rc_engineered'] == 1,\n",
    "                                                             categorical_dimension='foundation_type', numerical_dimension='age', df=join_df, ax=ax, ax_histx=axx,\n",
    "                                                             ax_histy=axy)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between Roof Type and Foundation Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = pd.get_dummies(join_df.loc[:, ['roof_type', 'foundation_type']]).corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background:**\n",
    "\n",
    "* In an earthquake-affected site, if a building inspector visits the site, then can he establish that the Average Age of RC Engineered Buildings will be higher for the Foundation Type (u) compared to other Foundation types.\n",
    "* The relation between Height Percentage and Foundation Types have been established.\n",
    "\n",
    "**Facts:**\n",
    "\n",
    "* FT (i) is most commonly occuring seismic vulnerability factor among the RC Engineered Superstructures with 3500+ buildings.\n",
    "* The Average Age for RC Engineered Superstructures is high for buildings with FT (u). \n",
    "* The average height for FT (i) for Modern Buildings is high but average age for FT (i) for RC Engineered is very low.\n",
    "* This suggests to conduct correlation analysis of Roof Type and Foundation Type\n",
    "* This indicates RT (x) and FT (i) are highly correlated\n",
    "* RT (x) could be assumed to be Truss Roof Type because of its appearance of large height and low age\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "* In the Scatter plot several buildings of FT 'u' deteriorated due to age (about 60 / 327 Modern Buildings)\n",
    "* FT (u) is definitely indicative of Age and deterioration due to age.\n",
    "* Roof Type is relevant because RT (x) has least seismic vulnerability factor, overall but it is correlated with FT (i) which is indicative of Average Height Percentage.\n",
    "\n",
    "**Answer to Research Question:**\n",
    "\n",
    "* The answer to research question using Scatter plot (Sub Visualization of RQ7) indicates the **Average Age for FT (u) is higher than FT (i)** for 327 Modern Buildings\n",
    "* The research question RQ7 - Main Plot also indicates that the **Average Age for FT (u) is higher than any other FT types**, but by how much is not known.\n",
    "* A building inspector visiting the site can establish that if the superstructure is **RC Engineered** and then the **Age is high (exactly 40 and above)**, with **40% certainty** the FT will be 'u'. (Please see the calculation in Sub Answer of RQ7 - below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question 7\n",
    "\n",
    "## Sub Answer of RQ7\n",
    "\n",
    "### Establishing the certainty with which the Average Age will be high Age for FT (u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_age_high_probability_by_simulation(age=25):\n",
    "    p_s = []\n",
    "    # 10 iterations\n",
    "    for i in range(10):\n",
    "        ages_probability = []\n",
    "        # 30 simulations of samples\n",
    "        for i in range(30):\n",
    "            # 100 buildings in a particular geographical region\n",
    "            sample_df = join_df.loc[join_df['has_superstructure_rc_engineered'] == 1].sample(100)\n",
    "            def foundation_type(ft):\n",
    "                s_df = sample_df.loc[sample_df['foundation_type'] == ft]\n",
    "                age_high = s_df.loc[s_df['age'] >= age].count().iloc[0]\n",
    "                return 0 if s_df.count().iloc[0] == 0 else age_high / s_df.count().iloc[0]\n",
    "            ft_h, ft_i, ft_r, ft_u, ft_w = foundation_type('h'), foundation_type('i'), foundation_type('r'), foundation_type('u'), foundation_type('w')\n",
    "            if sum((ft_h, ft_i, ft_r, ft_u, ft_w)) != 0:\n",
    "                ages_probability.append([ft_h, ft_i, ft_r, ft_u, ft_w])\n",
    "        ages_probability = np.array(ages_probability)\n",
    "        print(\"probability (h,i,r,u,w) = \", (ages_probability / ages_probability.sum(axis=1).reshape(-1,1)).mean(axis=0))\n",
    "        p_s.append((ages_probability / ages_probability.sum(axis=1).reshape(-1,1)).mean(axis=0).tolist())\n",
    "    p = np.array(p_s)\n",
    "    print(\"Average probability (h,i,r,u,w): \", (p / p.sum(axis=1).reshape(-1,1)).mean(axis=0))\n",
    "    \n",
    "evaluate_age_high_probability_by_simulation(age=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background:**\n",
    "\n",
    "* Calculation of the average probability over n number of iterations will result in a correct definition for what is high for Age and what is the probability to land on buildings with Foundation Type (u) when the age is high\n",
    "* RC Engineered buildings that have been daamged are constructed with FT (i) / Integrated type\n",
    "\n",
    "**Facts:**\n",
    "\n",
    "* A sample size of 100 is taken\n",
    "* 30 simulations are done for the 100 samples\n",
    "* 10 iterations are done on the 30 simulations\n",
    "* The probability of each (h,i,r,u,w) are calculated\n",
    "* The average probability of 'u' is taken into consideration for final answer\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "* The average probability turns out to be around **40%**\n",
    "\n",
    "**Answer to Research Question:**\n",
    "\n",
    "* When the average age is high (>= 40), then the building inspector can suggest that about 40% of times the assumption on higher average age for FT (u) is correct for RC Engineered Superstructures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is the Plot of Age vs Foundation Type Sliced by Superstructures - Timber, Cement Mortar Stone and Cement Mortar Brick as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Facts:**\n",
    "\n",
    "* Timber is greatly destroyed than RC Engineered Superstructures and also by 'r' FT rather than 'i' FT\n",
    "* Cement Mortar Brick are greatly destroyed than RC Engineered\n",
    "* Cement Mortar Stone is more or less equally destroyed when compared to RC Engineered Superstructures\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "* The Average Age is higher for 'r' FT in Timber, Cement Mortar Stone and Cement Mortar Brick Superstructures\n",
    "* The Average Age is higher for 'u' FT in RC Engineered Superstructures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the gridspec 2,2 with one main plot and 2 side plots on x and y axes respectively\n",
    "result = setup_gridspec__four_main__two_side_subplots(plt)\n",
    "# gridspec\n",
    "gs = result[\"gridspec\"]\n",
    "# axis\n",
    "ax1,ax2,ax3,ax4 = result[\"ax\"]\n",
    "# axis on top parallel to x-axis\n",
    "axx1,axx2,axx3,axx4 = result[\"axx\"]\n",
    "# axis on the side parallel to y-axis\n",
    "axy1,axy2,axy3,axy4 = result[\"axy\"]\n",
    "# figure of the plot\n",
    "fig = result[\"fig\"]\n",
    "\n",
    "plot_scatter_bubble_numerical_vs_categorical_bar_hist_sliced(sizes_tuple=(np.log, 1e2), xlabel='Foundation Type', ylabel='Avg. Age',\n",
    "                                                             sliced_by='Timber', slice_idx=join_df['has_superstructure_timber'] == 1,\n",
    "                                                             categorical_dimension='foundation_type', numerical_dimension='age', df=join_df, ax=ax1, ax_histx=axx1,\n",
    "                                                             ax_histy=axy1)\n",
    "plot_scatter_bubble_numerical_vs_categorical_bar_hist_sliced(sizes_tuple=(np.log, 1e2), xlabel='Foundation Type', ylabel='Avg. Age',\n",
    "                                                             sliced_by='RC Engineered', slice_idx=join_df['has_superstructure_rc_engineered'] == 1,\n",
    "                                                             categorical_dimension='foundation_type', numerical_dimension='age', df=join_df, ax=ax2, ax_histx=axx2,\n",
    "                                                             ax_histy=axy2)\n",
    "plot_scatter_bubble_numerical_vs_categorical_bar_hist_sliced(sizes_tuple=(np.log, 1e2), xlabel='Foundation Type', ylabel='Avg. Age',\n",
    "                                                             sliced_by='Cement Mortar Stone', slice_idx=join_df['has_superstructure_cement_mortar_stone'] == 1,\n",
    "                                                             categorical_dimension='foundation_type', numerical_dimension='age', df=join_df, ax=ax3, ax_histx=axx3,\n",
    "                                                             ax_histy=axy3)\n",
    "plot_scatter_bubble_numerical_vs_categorical_bar_hist_sliced(sizes_tuple=(np.log, 1e2), xlabel='Foundation Type', ylabel='Avg. Age',\n",
    "                                                             sliced_by='Cement Mortar Brick', slice_idx=join_df['has_superstructure_cement_mortar_brick'] == 1,\n",
    "                                                             categorical_dimension='foundation_type', numerical_dimension='age', df=join_df, ax=ax4, ax_histx=axx4,\n",
    "                                                             ax_histy=axy4)\n",
    "fig.suptitle(\"Age vs Foundation Type Sliced by Selected Superstructures Distinguished by Amount of Buildings Damaged\", y=0.92)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Research Question 8\n",
    "\n",
    "#### If a sample of hotels are taken from the population, what Foundation Type will have a relatively higher Average Area Percentage?\n",
    "\n",
    "### Count of Families vs Area Percentage and Count of Families vs Count of Floors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background:**\n",
    "\n",
    "* RQ8 asks for Hotels, hence a comparison between Large Hotel Buildings and Small Hotel Buildings need to be made to explore the trend of collapse of them.\n",
    "\n",
    "**Facts:**\n",
    "\n",
    "* Here, the above plot is marked in Rectangle with Large Buildings from area_percentage >= 45 and count_families_pre_eq >= 1\n",
    "* There is another plot which is marked with Populated Buildings indicating greater Count of Families per Building.\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "* There is a trend for the Area Percentage vs Count of Families plot. \n",
    "* The Maximum Area Percentage of the buildings get reduced when there are more families in the buildings, with Max Area Percentage of about 60 for count_families_pre_eq = 9 \n",
    "* If Hotels with Large Footprint area are taken into consideration, then collapse of the Foundation Types can be analysed. \n",
    "* Hotels with small footprint area with count of families >= 1 will give differences between former analysis and the current one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_area_percentage_vs_count_families(ax, colors):\n",
    "    \n",
    "    # Create Map\n",
    "    cm = plt.get_cmap(\"BuPu\")\n",
    "    data = join_df.sort_values('area_percentage').reset_index()\n",
    "    ax.scatter(data.area_percentage, data.count_families, s=180)\n",
    "    high_value_box = Rectangle((45, 0.8), 53, 4.5, fill=False, ls='dashed', lw=3, color=colors[8])\n",
    "    ax.add_patch(high_value_box)\n",
    "    ax.text(35, 5.5, \"Large Buildings\", fontsize=24, color=colors[6])\n",
    "    ax.set(xlabel=\"Area Percentage\", ylabel=\"Count of Families\", title=\"Count of Families vs Area Percentage showing Buildings with large footprint area\")\n",
    "    \n",
    "def plot_count_floors_vs_count_families(ax, colors):\n",
    "    \n",
    "    # Create Map\n",
    "    cm = plt.get_cmap(\"BuPu\")\n",
    "    data = join_df.sort_values('count_floors_pre_eq').reset_index()\n",
    "    ax.scatter(data.count_floors_pre_eq, data.count_families, s=180)\n",
    "    high_value_box = Rectangle((0.8, 2.8), 6.5, 6.2, fill=False, ls='dashed', lw=3, color=colors[8])\n",
    "    ax.add_patch(high_value_box)\n",
    "    ax.text(7.5, 6, \"Populated Buildings\", fontsize=24, color=colors[6])\n",
    "    ax.set(xlabel=\"Count of Floors\", ylabel=\"Count of Families\", title=\"Count of Families vs Count of Floors showing Buildings with large footprint area\")\n",
    "    \n",
    "fig, ax = plt.subplots(1,2,figsize=(18,6))\n",
    "colors = sns.color_palette(\"hls\", 10)\n",
    "plot_area_percentage_vs_count_families(ax[0], colors)\n",
    "plot_count_floors_vs_count_families(ax[1], colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of Area Percentage for Large Hotels and Small Hotels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background:**\n",
    "\n",
    "* The Hotels must vary between Large Hotel Buildings and Small Hotel Buildings, their Foundation Types should also vary. \n",
    "* This will give insights into the distribution of Area Percentage over Foundation Types\n",
    "\n",
    "**Facts:**\n",
    "\n",
    "* For Large Hotels, 'i' has a more taller distribution with greater Area Percentage\n",
    "* For Small Hotels, 'r' has a more larger distribution with lesser Area Percentage compared to Large Hotels\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "* 'i' shows more overall average area percentage because Large Hotels are mostly constructed with 'i' Foundation Type\n",
    "* 'r' shows lesser overall average area percentage because only Small Hotels dominate with 'r' Foundation Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hotels_foundation_types_average_age(ax1, colors, kind='large_hotels'):\n",
    "    if kind == 'large_hotels':\n",
    "        hotels_mask = (join_df['has_secondary_use_hotel'] == 1) & (join_df['area_percentage'] >= 45) & (join_df['count_families'] >= 1)\n",
    "        ax1.set(xlabel=\"Average Area Percentage\", ylabel=\"Count\", title=\"Average Area Percentage Histogram for Large Hotels\")\n",
    "    elif kind == 'small_hotels':\n",
    "        hotels_mask = (join_df['has_secondary_use_hotel'] == 1) & (join_df['area_percentage'] < 45) & (join_df['count_families'] >= 1)\n",
    "        ax1.set(xlabel=\"Average Area Percentage\", ylabel=\"Count\", title=\"Average Area Percentage Histogram for Small Hotels\")\n",
    "    hotels = join_df.loc[hotels_mask, ['area_percentage', 'foundation_type']]\n",
    "    ax1.hist(hotels[hotels['foundation_type'] == 'h'].area_percentage, color=colors[0], label=\"Foundation Type (h)\")\n",
    "    ax1.hist(hotels[hotels['foundation_type'] == 'i'].area_percentage, color=colors[1], label=\"Foundation Type (i)\")\n",
    "    ax1.hist(hotels[hotels['foundation_type'] == 'r'].area_percentage, color=colors[2], label=\"Foundation Type (r)\")\n",
    "    ax1.hist(hotels[hotels['foundation_type'] == 'u'].area_percentage, color=colors[3], label=\"Foundation Type (u)\")\n",
    "    ax1.hist(hotels[hotels['foundation_type'] == 'w'].area_percentage, color=colors[4], label=\"Foundation Type (w)\")\n",
    "    ax1.legend()\n",
    "    \n",
    "fig, ax = plt.subplots(1,2,figsize=(20,10))\n",
    "colors = sns.color_palette(\"hls\", 5)\n",
    "plot_hotels_foundation_types_average_age(ax[0], colors, kind='large_hotels')\n",
    "plot_hotels_foundation_types_average_age(ax[1], colors, kind='small_hotels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Research Question 8\n",
    "\n",
    "#### If a sample of hotels are taken from the population, what Foundation Type will have a relatively higher Average Area Percentage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Plot of Area Percentage and Damage Grade vs Foundation Type Sliced by Agricultural / Hotel / Rental / School Distinguished by Amount of Buildings Damaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# setup the gridspec 2,2 with one main plot and 2 side plots on x and y axes respectively\n",
    "result = setup_gridspec__one_main__two_side_subplots(plt)\n",
    "# gridspec\n",
    "gs = result[\"gridspec\"]\n",
    "# axis\n",
    "ax = result[\"ax\"]\n",
    "# axis on top parallel to x-axis\n",
    "axx = result[\"axx\"]\n",
    "# axis on the side parallel to y-axis\n",
    "axy = result[\"axy\"]\n",
    "# figure of the plot\n",
    "fig = result[\"fig\"]\n",
    "\n",
    "def plot_scatter_bubble_numerical_vs_categorical_bar_hist_sliced(sizes_tuple, xlabel, ylabel, sliced_by, slice_idx,\n",
    "                                                                 categorical_dimension, numerical_dimension, df, ax, ax_histx, ax_histy):\n",
    "    unique_colors = ['#88E0EF', '#161E54', '#FF5151', '#FF9B6A', '#BBDFC8']\n",
    "    var_df = df.loc[slice_idx, [numerical_dimension, categorical_dimension]].groupby(by=[categorical_dimension], as_index=False).count()\n",
    "    age_df = df.loc[slice_idx, [numerical_dimension, categorical_dimension]].groupby(by=[categorical_dimension], as_index=False).mean()\n",
    "    age_df.index = age_df[categorical_dimension]\n",
    "\n",
    "    assert len(unique_colors) == 5, \"Test #1 Failed\"\n",
    "    assert len(var_df[categorical_dimension]) == 5, \"Test #2 Failed\"\n",
    "    assert len(age_df[categorical_dimension]) == 5, \"Test #3 Failed\"\n",
    "    \n",
    "    # set xticks and xtick labels\n",
    "    ax.set_xticks(range(0,len(age_df[categorical_dimension])))\n",
    "    ax.set_xticklabels(age_df[categorical_dimension].values)\n",
    "    \n",
    "    assert [t.get_text() for t in ax.get_xticklabels()] == age_df[categorical_dimension].values.tolist(), \"Test #4 Failed\"\n",
    "    \n",
    "    counter_i = df.loc[slice_idx, [categorical_dimension]].value_counts().sort_index(ascending=True)\n",
    "    colors = dict(zip(age_df.index.values, unique_colors))\n",
    "    scatter = ax.scatter(age_df.index.values, age_df[numerical_dimension], c=[colors[ft] for ft in colors], s=sizes_tuple[0](var_df[numerical_dimension])*sizes_tuple[1])\n",
    "    ax.set(xlabel=xlabel, ylabel=ylabel)\n",
    "    ax.set_title(\"{ylabel} vs {xlabel} Sliced by {sliced_by}\".format(xlabel=xlabel, ylabel=ylabel, sliced_by=sliced_by))\n",
    "    custom_lines = [Line2D([0], [0], color=colors[dim], lw=4) for dim in age_df.index.values]\n",
    "    legend1 = ax.legend(custom_lines, age_df.index.values, loc=\"upper left\", title=\"Foundation Type\", framealpha=0.1)\n",
    "    ax.add_artist(legend1)\n",
    "    handles, labels = scatter.legend_elements(prop=\"sizes\", alpha=0.1)\n",
    "    legend2 = ax.legend(handles, labels, loc=\"upper right\", title=\"Log Damage Impact\", framealpha=0.1)\n",
    "    ax_histx.bar(counter_i.index.get_level_values(0), counter_i.values)\n",
    "    ax_histx.set(xlabel=xlabel, ylabel='Count')\n",
    "    ax_histx.set_title(\"Histogram of {xlabel}\".format(xlabel=xlabel))\n",
    "    \n",
    "    # set xticks and xtick labels\n",
    "    ax_histx.set_xticks(range(0,len(age_df[categorical_dimension])))\n",
    "    ax_histx.set_xticklabels(age_df[categorical_dimension].values)\n",
    "    \n",
    "    assert [t.get_text() for t in ax_histx.get_xticklabels()] == age_df[categorical_dimension].values.tolist(), \"Test #5 Failed\"\n",
    "    \n",
    "    ax_histy.barh(age_df[numerical_dimension], var_df[numerical_dimension])\n",
    "    ax_histy.set(xlabel='Count', ylabel=\"Damage Impact caused over Average Area Percentage grouped by Foundation Type\")\n",
    "    \n",
    "    fig.suptitle(\"Area Percentage vs Foundation Type Sliced by Hotels Distinguished by Amount of Buildings Damaged\", y=0.95)\n",
    "\n",
    "plot_scatter_bubble_numerical_vs_categorical_bar_hist_sliced(sizes_tuple=(np.log, 1e2), xlabel='Foundation Type', ylabel='Avg. Area Percentage',\n",
    "                                                             sliced_by='Hotel', slice_idx=join_df['has_secondary_use_hotel'] == 1,\n",
    "                                                             categorical_dimension='foundation_type', numerical_dimension='area_percentage', df=join_df, ax=ax, ax_histx=axx,\n",
    "                                                             ax_histy=axy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background:**\n",
    "\n",
    "* In an earthquake-affected site, if a building inspector inspects the site, and found out that the afootprint area (area percentage) is high for the collapsed building, then can he establish whether the Foundation Type will be 'i'\n",
    "* The relation between Count of Families and Area Percentage has been established. \n",
    "\n",
    "**Facts:**\n",
    "\n",
    "* Some Large buildings have been identified in the Previous Plots. \n",
    "* Hotel Buildings are found to have greater amount of buildings for 'r' FT compared to 'i' FT which can be observed from the top histogram bar plot of Foundation Types\n",
    "* Large Hotel Buildings and Small Hotel Buildings have been taken for analysis in the Previous Plot\n",
    "* The distribution of 'i' over Small and Large are unknown, hence a Histogram is used to show the difference\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "* The Histogram reveals that 'i' FT is seen largely in Large Hotel Buildings and it is because of that the overall average is highest in above Scatter / Bubble Plot\n",
    "* The small value for 'h' in the side histogram is not visible due to a scale, and that has been adjusted as Log Damage Impact in the Scatter / Bubble plot above\n",
    "\n",
    "**Answer to Research Question:**\n",
    "\n",
    "* **The building inspector** will be able to assume the mean of the sample is same as the mean of the population, by inference by simulation\n",
    "* **The building inspector** would be able to say that the Average height of FT (i) will be high with **42 - 44% certainty**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub Answer of RQ8\n",
    "\n",
    "### Calculating the Certainty with which Average height of FT (i) will be high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_area_high_probability_by_simulation(area_percentage=25):\n",
    "    p_s = []\n",
    "    # 10 iterations\n",
    "    for i in range(10):\n",
    "        areas_probability = []\n",
    "        # 30 simulations of samples\n",
    "        for i in range(30):\n",
    "            # 100 buildings in a particular geographical region\n",
    "            sample_df = join_df.loc[join_df['has_secondary_use_hotel'] == 1].sample(100)\n",
    "            def foundation_type(ft):\n",
    "                s_df = sample_df.loc[sample_df['foundation_type'] == ft]\n",
    "                area_high = s_df.loc[s_df['area_percentage'] >= area_percentage].count().iloc[0]\n",
    "                return 0 if s_df.count().iloc[0] == 0 else area_high / s_df.count().iloc[0]\n",
    "            ft_h, ft_i, ft_r, ft_u, ft_w = foundation_type('h'), foundation_type('i'), foundation_type('r'), foundation_type('u'), foundation_type('w')\n",
    "            if sum((ft_h, ft_i, ft_r, ft_u, ft_w)) != 0:\n",
    "                areas_probability.append([ft_h, ft_i, ft_r, ft_u, ft_w])\n",
    "        areas_probability = np.array(areas_probability)\n",
    "        print(\"probability (h,i,r,u,w) = \", (areas_probability / areas_probability.sum(axis=1).reshape(-1,1)).mean(axis=0))\n",
    "        p_s.append((areas_probability / areas_probability.sum(axis=1).reshape(-1,1)).mean(axis=0).tolist())\n",
    "    p = np.array(p_s)\n",
    "    print(\"Average probability (h,i,r,u,w): \", (p / p.sum(axis=1).reshape(-1,1)).mean(axis=0))\n",
    "    \n",
    "evaluate_area_high_probability_by_simulation(area_percentage=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Research Question 9\n",
    "\n",
    "#### What is the Damage Grade for each Plan Configuration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from IPython.display import SVG, Image\n",
    "\n",
    "def preprocess_plan_configuration_vs_damage_grade():\n",
    "    plan_configuration = join_df.groupby(['plan_configuration','damage_grade']).size().reset_index(name='percentage')\n",
    "    plan_configuration = plan_configuration.set_index(['plan_configuration', 'damage_grade'])\n",
    "    plan_configuration = plan_configuration.groupby(level=0).apply(lambda x: round(100 * x / float(x.sum()),2)).reset_index()\n",
    "    plan_configuration = plan_configuration.astype({'plan_configuration': 'string', 'damage_grade': 'string'})\n",
    "    plan_configuration['plan_configuration'] = \"Plan Configuration: \" + plan_configuration['plan_configuration']\n",
    "    plan_configuration['damage_grade'] = \"Damage Grade: \" + plan_configuration['damage_grade']\n",
    "    plan_configuration.drop(labels=plan_configuration[plan_configuration['percentage'] == 0].index, inplace=True)\n",
    "    \n",
    "    return plan_configuration\n",
    "\n",
    "def plot_plan_configuration_vs_damage_grade(plan_configuration):\n",
    "    fig = px.treemap(plan_configuration, path=['plan_configuration','damage_grade', 'percentage'], values='percentage',\n",
    "                 color='percentage', hover_data=['damage_grade'],\n",
    "                 color_continuous_scale='RdBu')\n",
    "    fig.update_layout(margin = dict(t=50, l=25, r=25, b=25))\n",
    "    img_bytes = pio.to_image(fig, format=\"svg\", engine=\"kaleido\", width=1024, height=960)\n",
    "    return img_bytes\n",
    "    \n",
    "plan_configuration = preprocess_plan_configuration_vs_damage_grade()\n",
    "SVG(plot_plan_configuration_vs_damage_grade(plan_configuration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Statistics\n",
    "\n",
    "* Statistical Methods\n",
    "* Help Answer Research Questions\n",
    "* Outliers and Boxplots\n",
    "* Eigen Vectors and Eigen Values (Understanding the Domain)\n",
    "* Principal Components Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Box Plot of Numerical Measures\n",
    "\n",
    "* To find outliers and extreme values\n",
    "* To determine skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a=1\n",
    "plt.figure(figsize=(24,12))\n",
    "plt.tight_layout(pad=0.5)\n",
    "for attr in numerical_measures:\n",
    "    plt.subplot(3,2,a)\n",
    "    ax=sns.boxplot(join_df[attr], color='y')\n",
    "    plt.xlabel(attr, fontsize=20)\n",
    "    a+=1\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
